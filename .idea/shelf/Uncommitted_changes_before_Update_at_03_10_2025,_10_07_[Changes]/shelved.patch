Index: UI/UIApp.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import streamlit as st\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport yaml\nimport json\nimport os\nfrom UI.UIhelper import PipelineHelper\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Page configuration\nst.set_page_config(\n    page_title=\"Horse Racing Pipeline\",\n    page_icon=\"\uD83C\uDFC7\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Custom CSS for color palette\nst.markdown(\"\"\"\n<style>\n    /* Color palette: #244855 / #E64833 / #874F41 / #90AEAD / #FBE9D0 */\n\n    .stApp {\n        background-color: #FBE9D0;\n    }\n\n    .stSidebar {\n        background-color: #244855;\n    }\n\n    .stSidebar .stMarkdown,\n    .stSidebar .stRadio label,\n    .stSidebar h2 {\n        color: #FBE9D0 !important;\n    }\n\n    .stSidebar .stRadio > div {\n        background-color: transparent;\n        padding: 1rem;\n    }\n\n    .stSidebar .stRadio > div > label {\n        display: flex;\n        align-items: center;\n        cursor: pointer;\n        margin: 0.25rem 0;\n    }\n\n    .stSidebar .stRadio > div > label > div:first-child {\n        display: none !important; /* Hide radio button */\n    }\n\n    .stSidebar .stRadio > div > label > div:last-child {\n        background: rgba(251, 233, 208, 0.1) !important;\n        backdrop-filter: blur(10px);\n        color: #FBE9D0 !important;\n        font-weight: 500;\n        padding: 0.75rem 1rem;\n        border-radius: 8px;\n        border: 1px solid rgba(251, 233, 208, 0.2);\n        width: 100%;\n        transition: all 0.3s ease;\n    }\n\n    .stSidebar .stRadio > div > label > div:last-child:hover {\n        background: rgba(251, 233, 208, 0.2) !important;\n        border: 1px solid rgba(230, 72, 51, 0.5);\n        transform: translateY(-1px);\n    }\n\n    .main-header {\n        background-color: #244855;\n        color: #FBE9D0;\n        padding: 2rem;\n        border-radius: 10px;\n        margin-bottom: 2rem;\n        text-align: center;\n    }\n\n    .config-panel {\n        background-color: #90AEAD;\n        color: #244855;\n        padding: 2rem;\n        border-radius: 10px;\n        margin-bottom: 1rem;\n        border: 1px solid #874F41;\n    }\n\n    .output-panel {\n        background-color: #874F41;\n        color: #FBE9D0;\n        padding: 2rem;\n        border-radius: 10px;\n        margin-bottom: 1rem;\n        border: 1px solid #244855;\n    }\n\n    .stButton > button {\n        background-color: #E64833;\n        color: #FBE9D0;\n        border: none;\n        border-radius: 8px;\n        padding: 0.75rem 1.5rem;\n        font-weight: bold;\n        transition: all 0.3s ease;\n    }\n\n    .stButton > button:hover {\n        background-color: #E64833;\n        backdrop-filter: blur(10px);\n        box-shadow: 0 8px 32px rgba(230, 72, 51, 0.3);\n        transform: translateY(-2px);\n    }\n\n    .success-message {\n        background-color: #90AEAD;\n        color: #244855;\n        padding: 1rem;\n        border-radius: 5px;\n        margin: 1rem 0;\n        border-left: 4px solid #244855;\n    }\n\n    .error-message {\n        background-color: #E64833;\n        color: #FBE9D0;\n        padding: 1rem;\n        border-radius: 5px;\n        margin: 1rem 0;\n        border-left: 4px solid #244855;\n    }\n</style>\n\"\"\", unsafe_allow_html=True)\n\n# Initialize session state and helper\nif 'output_logs' not in st.session_state:\n    st.session_state.output_logs = []\nif 'helper' not in st.session_state:\n    st.session_state.helper = PipelineHelper()\nif 'config_loaded' not in st.session_state:\n    st.session_state.config_loaded = False\nif 'training_active' not in st.session_state:\n    st.session_state.training_active = False\n\n\n# Config management functions\ndef load_config():\n    \"\"\"Load config.yaml file\"\"\"\n    try:\n        config_path = 'config.yaml'\n        if os.path.exists(config_path):\n            with open(config_path, 'r') as file:\n                config_data = yaml.safe_load(file)\n                st.session_state.config_data = config_data\n                st.session_state.config_loaded = True\n                log_output(\"Configuration loaded successfully\", \"success\")\n                return config_data\n        else:\n            log_output(\"config.yaml not found\", \"error\")\n            return None\n    except Exception as e:\n        log_output(f\"Error loading config: {str(e)}\", \"error\")\n        return None\n\n\ndef save_config(updated_config):\n    \"\"\"Save updated config to config.yaml\"\"\"\n    try:\n        config_path = 'config.yaml'\n        with open(config_path, 'w') as file:\n            yaml.dump(updated_config, file, default_flow_style=False, sort_keys=False)\n        st.session_state.config_data = updated_config\n        log_output(\"Configuration saved successfully\", \"success\")\n        return True\n    except Exception as e:\n        log_output(f\"Error saving config: {str(e)}\", \"error\")\n        return False\n\n\ndef display_config_json():\n    \"\"\"Display current config as formatted JSON\"\"\"\n    if st.session_state.config_data:\n        return json.dumps(st.session_state.config_data, indent=2)\n    return \"No configuration loaded\"\n\n\n# Helper functions (placeholders for now)\ndef log_output(message, message_type=\"info\"):\n    \"\"\"Add message to output logs\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    st.session_state.output_logs.append({\n        \"timestamp\": timestamp,\n        \"message\": message,\n        \"type\": message_type\n    })\n\n\ndef clear_logs():\n    \"\"\"Clear output logs\"\"\"\n    st.session_state.output_logs = []\n\n\ndef display_logs():\n    \"\"\"Display output logs\"\"\"\n    if st.session_state.output_logs:\n        st.markdown(\"### \uD83D\uDCCB Output Logs\")\n        for log in st.session_state.output_logs[-10:]:  # Show last 10 logs\n            if log[\"type\"] == \"success\":\n                st.markdown(f'<div class=\"success-message\">[{log[\"timestamp\"]}] ✅ {log[\"message\"]}</div>',\n                            unsafe_allow_html=True)\n            elif log[\"type\"] == \"error\":\n                st.markdown(f'<div class=\"error-message\">[{log[\"timestamp\"]}] ❌ {log[\"message\"]}</div>',\n                            unsafe_allow_html=True)\n            else:\n                st.write(f'[{log[\"timestamp\"]}] ℹ\uFE0F {log[\"message\"]}')\n\n\n# Placeholder functions for pipeline operations\ndef mysql_sqlite_sync(db):\n    \"\"\"Placeholder for MySQL to SQLite sync\"\"\"\n    log_output(\"Starting MySQL to SQLite synchronization...\", \"info\")\n    from core.orchestrators.mysql_sqlite_sync import sync_data\n    sync_data(db)\n    log_output(\"MySQL to SQLite sync completed successfully!\", \"success\")\n\n\ndef execute_full_training(progress_bar, status_text):\n    \"\"\"Execute full training using pipeline helper with async support\"\"\"\n\n    # Check if training is already running\n    if st.session_state.helper.is_training:\n        # Training in progress - check for updates\n        updates = st.session_state.helper.get_training_updates()\n\n        for update in updates:\n            if update['type'] == 'progress':\n                progress_bar.progress(update['percent'])\n                status_text.text(f\"Progress: {update['percent']}% - {update['message']}\")\n                log_output(update['message'], \"info\")\n            elif update['type'] == 'complete':\n                if update['success']:\n                    progress_bar.progress(100)\n                    status_text.text(\"Training completed!\")\n                    log_output(update['message'], \"success\")\n                else:\n                    progress_bar.progress(0)\n                    status_text.text(\"Training failed!\")\n                    log_output(update['message'], \"error\")\n\n                # Clear training state\n                st.session_state.training_active = False\n\n        # Auto-refresh if still training\n        if st.session_state.helper.is_training:\n            st.session_state.training_active = True\n            # This will cause the UI to refresh and check again\n            return\n    else:\n        # Not training - start new training\n        log_output(\"Starting background training...\", \"info\")\n\n        if st.session_state.helper.start_training_async():\n            progress_bar.progress(0)\n            status_text.text(\"Training started in background...\")\n            st.session_state.training_active = True\n            log_output(\"Training started successfully in background\", \"success\")\n        else:\n            log_output(\"Failed to start training\", \"error\")\n\n\ndef execute_predictions(selected_races, progress_bar, status_text, force_reprediction=False):\n    \"\"\"Execute predictions using pipeline helper\"\"\"\n    prediction_type = \"force reprediction\" if force_reprediction else \"standard prediction\"\n    log_output(f\"Starting race {prediction_type}...\", \"info\")\n\n    def progress_callback(percentage, message):\n        \"\"\"Callback function to update progress\"\"\"\n        progress_bar.progress(percentage)\n        status_text.text(f\"Progress: {percentage}% - {message}\")\n        log_output(message, \"info\")\n\n    try:\n        result = st.session_state.helper.execute_predictions(\n            races_to_predict=selected_races if selected_races else None,\n            progress_callback=progress_callback,\n            force_reprediction=force_reprediction\n        )\n\n        if result[\"success\"]:\n            progress_bar.progress(100)\n            status_text.text(\"Predictions completed!\")\n            log_output(result[\"message\"], \"success\")\n        else:\n            progress_bar.progress(0)\n            status_text.text(\"Predictions failed!\")\n            log_output(result[\"message\"], \"error\")\n\n    except Exception as e:\n        progress_bar.progress(0)\n        status_text.text(\"Prediction error!\")\n        log_output(f\"Prediction error: {str(e)}\", \"error\")\n\n\ndef execute_comprehensive_evaluation(progress_bar, status_text):\n    \"\"\"Execute comprehensive evaluation using new PredictEvaluator\"\"\"\n    log_output(\"Starting comprehensive evaluation...\", \"info\")\n\n    def progress_callback(percentage, message):\n        \"\"\"Callback function to update progress\"\"\"\n        progress_bar.progress(percentage)\n        status_text.text(f\"Progress: {percentage}% - {message}\")\n        log_output(message, \"info\")\n\n    try:\n        result = st.session_state.helper.evaluate_all_predictions_comprehensive(progress_callback=progress_callback)\n\n        if result[\"success\"]:\n            progress_bar.progress(100)\n            status_text.text(\"Comprehensive evaluation completed!\")\n            log_output(result[\"message\"], \"success\")\n\n            # Store results in session state for display\n            st.session_state.evaluation_results = result\n\n        else:\n            progress_bar.progress(0)\n            status_text.text(\"Evaluation failed!\")\n            log_output(result[\"message\"], \"error\")\n\n    except Exception as e:\n        progress_bar.progress(0)\n        status_text.text(\"Evaluation error!\")\n        log_output(f\"Evaluation error: {str(e)}\", \"error\")\n\n\ndef display_evaluation_charts(chart_data):\n    \"\"\"Display evaluation charts using Plotly\"\"\"\n\n    # Overall Performance Summary\n    st.markdown(\"### \uD83D\uDCCA Overall Performance\")\n    summary = chart_data['overall_summary']\n\n    col1, col2, col3, col4 = st.columns(4)\n    with col1:\n        st.metric(\"Total Races\", summary['total_races'])\n    with col2:\n        st.metric(\"Winner Accuracy\", f\"{summary['winner_accuracy']:.1f}%\")\n    with col3:\n        st.metric(\"Podium Accuracy\", f\"{summary['podium_accuracy']:.1f}%\")\n    with col4:\n        st.metric(\"Total Winning Bets\", summary['total_winning_bets'])\n\n    # Bet Type Performance Chart\n    if chart_data['bet_performance']:\n        st.markdown(\"### \uD83C\uDFAF Bet Type Performance\")\n\n        bet_df = pd.DataFrame(chart_data['bet_performance'])\n\n        # Create side-by-side charts\n        col1, col2 = st.columns(2)\n\n        with col1:\n            # Win Rate Bar Chart\n            fig_winrate = px.bar(\n                bet_df,\n                x='win_rate',\n                y='bet_type',\n                orientation='h',\n                title=\"Win Rate by Bet Type (%)\",\n                color='win_rate',\n                color_continuous_scale=['#E64833', '#90AEAD', '#244855'],\n                text='win_rate'\n            )\n            fig_winrate.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n            fig_winrate.update_layout(\n                showlegend=False,\n                height=400,\n                paper_bgcolor='rgba(0,0,0,0)',\n                plot_bgcolor='rgba(0,0,0,0)'\n            )\n            st.plotly_chart(fig_winrate, use_container_width=True)\n\n        with col2:\n            # Wins vs Losses Stacked Bar\n            fig_wins = go.Figure(data=[\n                go.Bar(name='Wins', y=bet_df['bet_type'], x=bet_df['wins'],\n                       orientation='h', marker_color='#90AEAD'),\n                go.Bar(name='Losses', y=bet_df['bet_type'], x=bet_df['losses'],\n                       orientation='h', marker_color='#E64833')\n            ])\n            fig_wins.update_layout(\n                barmode='stack',\n                title=\"Wins vs Losses by Bet Type\",\n                height=400,\n                paper_bgcolor='rgba(0,0,0,0)',\n                plot_bgcolor='rgba(0,0,0,0)'\n            )\n            st.plotly_chart(fig_wins, use_container_width=True)\n\n        # Detailed table\n        st.markdown(\"**Detailed Bet Performance**\")\n        display_df = bet_df[['bet_type', 'wins', 'total', 'win_rate']].copy()\n        display_df.columns = ['Bet Type', 'Wins', 'Total Races', 'Win Rate (%)']\n        display_df['Win Rate (%)'] = display_df['Win Rate (%)'].round(1)\n        st.dataframe(display_df, hide_index=True, use_container_width=True)\n\n    # Quinte Analysis\n    if chart_data.get('quinte_summary'):\n        st.markdown(\"### \uD83C\uDF1F Quinte Performance\")\n\n        quinte = chart_data['quinte_summary']\n        left, center, right = st.columns(3)\n        with left:\n            st.metric(\"Quinte Races\", quinte['total_quinte_races'])\n        with center:\n            st.metric(\"Quinte Winner Accuracy\", f\"{quinte['winner_accuracy']:.1f}%\")\n        with right:\n            st.metric(\"Quinte Bet Win Rate\", f\"{quinte['quinte_bet_win_rate']:.1f}%\")\n\n        # Quinte Horse Strategy Analysis\n        if chart_data['quinte_strategy']:\n            st.markdown(\"### \uD83D\uDC0E Quinte Betting Strategy Analysis\")\n\n            strategy_df = pd.DataFrame(chart_data['quinte_strategy'])\n\n            # Strategy comparison chart\n            fig_strategy = px.bar(\n                strategy_df,\n                x='strategy',\n                y='win_rate',\n                title=\"Win Rate by Number of Horses\",\n                color='win_rate',\n                color_continuous_scale=['#E64833', '#874F41', '#244855'],\n                text='win_rate'\n            )\n            fig_strategy.update_traces(texttemplate='%{text:.1f}%', textposition='outside')\n            fig_strategy.update_layout(\n                showlegend=False,\n                height=400,\n                paper_bgcolor='rgba(0,0,0,0)',\n                plot_bgcolor='rgba(0,0,0,0)',\n                xaxis_title=\"Betting Strategy\",\n                yaxis_title=\"Win Rate (%)\"\n            )\n            st.plotly_chart(fig_strategy, use_container_width=True)\n\n            # Recommendations\n            st.markdown(\"### \uD83D\uDCA1 Betting Recommendations\")\n\n            base_rate = strategy_df[strategy_df['strategy'] == '5 Horses']['win_rate'].iloc[0]\n            rate_6 = strategy_df[strategy_df['strategy'] == '6 Horses']['win_rate'].iloc[0]\n            rate_7 = strategy_df[strategy_df['strategy'] == '7 Horses']['win_rate'].iloc[0]\n\n            improvement_6 = rate_6 - base_rate\n            improvement_7 = rate_7 - base_rate\n\n            subleft, subright = st.columns(2)\n\n            with subleft:\n                st.markdown(\"**6-Horse Strategy**\")\n                if improvement_6 > 5:  # 5% improvement threshold\n                    st.success(f\"✅ Significant improvement: +{improvement_6:.1f}%\")\n                    st.info(\"\uD83C\uDFAF **Recommended:** Using 6 horses shows strong results\")\n                elif improvement_6 > 0:\n                    st.warning(f\"⚠\uFE0F Modest improvement: +{improvement_6:.1f}%\")\n                    st.info(\"\uD83D\uDCAD Consider cost vs benefit\")\n                else:\n                    st.error(f\"❌ No improvement: {improvement_6:+.1f}%\")\n                    st.info(\"\uD83D\uDEAB **Not recommended:** Stick with 5 horses\")\n\n            with subright:\n                st.markdown(\"**7-Horse Strategy**\")\n                if improvement_7 > 10:  # 10% improvement threshold for 7 horses\n                    st.success(f\"✅ Strong improvement: +{improvement_7:.1f}%\")\n                    st.info(\"\uD83C\uDFAF **Recommended:** 7 horses worth the extra cost\")\n                elif improvement_7 > improvement_6:\n                    st.warning(f\"⚠\uFE0F Better than 6 horses: +{improvement_7:.1f}%\")\n                    st.info(\"\uD83D\uDCAD Compare with 6-horse strategy\")\n                else:\n                    st.error(f\"❌ Not recommended: {improvement_7:+.1f}%\")\n                    st.info(\"\uD83D\uDEAB **Avoid:** Extra cost not justified\")\n\n            # Cost-benefit analysis\n            st.markdown(\"### \uD83D\uDCB0 Cost-Benefit Analysis\")\n\n            cost_multiplier_6 = 6 / 5  # 20% more combinations\n            cost_multiplier_7 = 7 / 5  # 40% more combinations\n\n            if improvement_6 > 0:\n                roi_6 = improvement_6 / ((cost_multiplier_6 - 1) * 100)\n                st.info(f\"**6-Horse ROI:** {roi_6:.1f}x return on extra investment\")\n\n            if improvement_7 > 0:\n                roi_7 = improvement_7 / ((cost_multiplier_7 - 1) * 100)\n                st.info(f\"**7-Horse ROI:** {roi_7:.1f}x return on extra investment\")\n\n    else:\n        st.info(\"No quinte races found for strategy analysis\")\n\n\ndef execute_incremental_training(date_from, date_to, limit, update_model, create_enhanced,\n                                archive_after, progress_bar, status_text):\n    \"\"\"Execute incremental training using regression enhancement pipeline\"\"\"\n    log_output(\"Starting incremental training with regression enhancement...\", \"info\")\n\n    def progress_callback(percentage, message):\n        \"\"\"Callback function to update progress\"\"\"\n        progress_bar.progress(percentage)\n        status_text.text(f\"Progress: {percentage}% - {message}\")\n        log_output(message, \"info\")\n\n    try:\n        result = st.session_state.helper.execute_incremental_training(\n            date_from=date_from,\n            date_to=date_to,\n            limit=limit,\n            update_model=update_model,\n            create_enhanced=create_enhanced,\n            archive_after=archive_after,\n            progress_callback=progress_callback\n        )\n\n        if result[\"success\"]:\n            progress_bar.progress(100)\n            status_text.text(\"Incremental training completed!\")\n            log_output(result[\"message\"], \"success\")\n            st.session_state.incremental_results = result\n        else:\n            progress_bar.progress(0)\n            status_text.text(\"Incremental training failed!\")\n            log_output(result[\"message\"], \"error\")\n\n    except Exception as e:\n        progress_bar.progress(0)\n        status_text.text(\"Training error!\")\n        log_output(f\"Incremental training error: {str(e)}\", \"error\")\n\n\n\n# Main application\ndef main():\n    # Header\n    st.markdown(\"\"\"\n    <div class=\"main-header\">\n        <h1>\uD83C\uDFC7 Horse Racing Prediction Pipeline</h1>\n        <p>Comprehensive data processing and model management interface</p>\n    </div>\n    \"\"\", unsafe_allow_html=True)\n    st.markdown(\"\"\"\n    <script>\n    window.parent.document.querySelector('[data-testid=\"stSidebar\"]').setAttribute('data-theme', 'light');\n    </script>\n    \"\"\", unsafe_allow_html=True)\n    # Sidebar navigation\n    st.sidebar.markdown(\"## \uD83D\uDE80 Pipeline Operations\")\n\n    operation = st.sidebar.radio(\n        \"Choose Operation:\",\n        [\n            \"\uD83C\uDFB2 Execute Prediction\",\n            \"✨ AI Insight\",\n            \"\uD83D\uDCC8 Execute Evaluation\",\n            \"\uD83D\uDD04 Incremental Training\",\n            \"\uD83C\uDFAF Execute Full Training\",\n            \"\uD83D\uDD04 MySQL ↔ SQLite Sync\",\n            \"⚙\uFE0F Update Config.yaml\",\n        ],\n        index=0\n    )\n\n    # Main content area\n    col1, col2 = st.columns([2, 1])\n\n    with col1:\n        # Configuration panel\n        with st.container():\n            if operation == \"\uD83D\uDD04 MySQL ↔ SQLite Sync\":\n                st.markdown('''\n                <div class=\"config-panel\">\n                    <h3> \uD83D\uDD04 MySQL to SQLite Synchronization</h3>\n                    <!-- Other content here -->\n                </div>\n                ''', unsafe_allow_html=True)\n\n                mysql_db = st.selectbox(\n                    \"MySQL Database:\",\n                    [\"pturf2024\", \"pturf2025\", \"custom\"]\n                )\n\n                if mysql_db == \"custom\":\n                    custom_db = st.text_input(\"Custom Database Name:\")\n                    mysql_db = custom_db if custom_db else \"pturf2025\"\n\n                st.info(\"This will synchronize race data from MySQL to SQLite database.\")\n\n                if st.button(\"\uD83D\uDE80 Start Sync\", key=\"sync_btn\"):\n                    if mysql_db:\n                        mysql_sqlite_sync(mysql_db)\n                    else:\n                        mysql_sqlite_sync(custom_db)\n\n                st.markdown('</div>', unsafe_allow_html=True)\n            elif operation == \"⚙\uFE0F Update Config.yaml\":\n                st.markdown('''\n                <div class=\"config-panel\">\n                    <h3> ⚙\uFE0F Configuration Management</h3>\n                    <!-- Other content here -->\n                </div>\n                ''', unsafe_allow_html=True)\n\n                # Load config on first visit or refresh\n                if not st.session_state.config_loaded:\n                    try:\n                        st.session_state.helper.load_config()\n                        st.session_state.config_loaded = True\n                        log_output(\"Configuration loaded successfully\", \"success\")\n                    except Exception as e:\n                        log_output(f\"Error loading config: {str(e)}\", \"error\")\n\n                # Refresh button\n                if st.button(\"\uD83D\uDD04 Refresh Config\", key=\"refresh_config\"):\n                    try:\n                        st.session_state.helper.load_config()\n                        log_output(\"Configuration refreshed\", \"success\")\n                        st.rerun()\n                    except Exception as e:\n                        log_output(f\"Error refreshing config: {str(e)}\", \"error\")\n\n                if st.session_state.config_loaded:\n                    # Create tabs for different config sections\n                    tab1, tab2, tab3 = st.tabs([\"\uD83D\uDCDD Edit Settings\", \"\uD83D\uDCCB View Full Config\", \"\uD83D\uDCBE Advanced\"])\n\n                    with tab1:\n                        config_sections = st.session_state.helper.get_config_sections()\n\n                        # Base Configuration\n                        st.markdown(\"**Base Settings**\")\n                        col1_base, col2_base = st.columns(2)\n                        with col1_base:\n                            if config_sections['base']:\n                                db_options = st.session_state.helper.get_sqlite_databases()\n                                current_active = config_sections['base'].get('active_db', 'full')\n\n                                if current_active in db_options:\n                                    active_db_index = db_options.index(current_active)\n                                else:\n                                    active_db_index = 0\n\n                                new_active_db = st.selectbox(\n                                    \"Active Database:\",\n                                    options=db_options,\n                                    index=active_db_index,\n                                    key=\"active_db_select\"\n                                )\n\n                        with col2_base:\n                            if config_sections['features']:\n                                new_embedding_dim = st.number_input(\n                                    \"Embedding Dimension:\",\n                                    min_value=4, max_value=64,\n                                    value=config_sections['features'].get('embedding_dim', 8),\n                                    key=\"embedding_dim_input\"\n                                )\n\n                        # LSTM Configuration\n                        st.markdown(\"**LSTM Settings**\")\n                        col1_lstm, col2_lstm = st.columns(2)\n                        with col1_lstm:\n                            if config_sections['lstm']:\n                                new_seq_length = st.number_input(\n                                    \"Sequence Length:\",\n                                    min_value=1, max_value=20,\n                                    value=config_sections['lstm'].get('sequence_length', 5),\n                                    key=\"seq_length_input\"\n                                )\n\n                        with col2_lstm:\n                            if config_sections['lstm']:\n                                new_step_size = st.number_input(\n                                    \"Step Size:\",\n                                    min_value=1, max_value=5,\n                                    value=config_sections['lstm'].get('step_size', 1),\n                                    key=\"step_size_input\"\n                                )\n\n                        # Dataset Configuration\n                        st.markdown(\"**Dataset Settings**\")\n                        col1_dataset, col2_dataset = st.columns(2)\n                        with col1_dataset:\n                            if config_sections['dataset']:\n                                new_test_size = st.slider(\n                                    \"Test Size:\",\n                                    min_value=0.1, max_value=0.5, step=0.05,\n                                    value=config_sections['dataset'].get('test_size', 0.2),\n                                    key=\"test_size_input\"\n                                )\n\n                        with col2_dataset:\n                            if config_sections['dataset']:\n                                new_val_size = st.slider(\n                                    \"Validation Size:\",\n                                    min_value=0.05, max_value=0.3, step=0.05,\n                                    value=config_sections['dataset'].get('val_size', 0.1),\n                                    key=\"val_size_input\"\n                                )\n\n                        # Cache Configuration\n                        st.markdown(\"**Cache Settings**\")\n                        if config_sections['cache']:\n                            new_use_cache = st.checkbox(\n                                \"Enable Cache\",\n                                value=config_sections['cache'].get('use_cache', True),\n                                key=\"use_cache_input\"\n                            )\n\n                        # Save button\n                        if st.button(\"\uD83D\uDCBE Save Configuration\", key=\"save_config_btn\"):\n                            try:\n                                # Prepare updates\n                                updates = {}\n                                if 'base' in config_sections:\n                                    updates['base'] = {'active_db': new_active_db}\n                                if 'features' in config_sections:\n                                    updates['features'] = {'embedding_dim': new_embedding_dim}\n                                if 'lstm' in config_sections:\n                                    updates['lstm'] = {'sequence_length': new_seq_length, 'step_size': new_step_size}\n                                if 'dataset' in config_sections:\n                                    updates['dataset'] = {'test_size': new_test_size, 'val_size': new_val_size}\n                                if 'cache' in config_sections:\n                                    updates['cache'] = {'use_cache': new_use_cache}\n\n                                # Update each section\n                                config_copy = st.session_state.helper._config_data.copy()\n                                for section, section_updates in updates.items():\n                                    if section in config_copy:\n                                        config_copy[section].update(section_updates)\n\n                                st.session_state.helper.save_config(config_copy)\n                                log_output(\"Configuration saved successfully\", \"success\")\n                                st.rerun()\n                            except Exception as e:\n                                log_output(f\"Error saving config: {str(e)}\", \"error\")\n\n                    with tab2:\n                        st.subheader(\"Complete Configuration\")\n                        st.code(st.session_state.helper.get_config_json(), language=\"json\")\n\n                    with tab3:\n                        st.subheader(\"Advanced Options\")\n                        st.warning(\"⚠\uFE0F Advanced configuration editing - use with caution\")\n\n                        # Text area for manual editing\n                        config_text = st.text_area(\n                            \"Edit YAML directly:\",\n                            value=yaml.dump(st.session_state.helper._config_data, default_flow_style=False),\n                            height=300,\n                            key=\"manual_config_edit\"\n                        )\n\n                        if st.button(\"\uD83D\uDCBE Save Manual Changes\", key=\"save_manual_config\"):\n                            try:\n                                manual_config = yaml.safe_load(config_text)\n                                st.session_state.helper.save_config(manual_config)\n                                log_output(\"Manual configuration saved successfully\", \"success\")\n                                st.rerun()\n                            except yaml.YAMLError as e:\n                                log_output(f\"Invalid YAML format: {str(e)}\", \"error\")\n                            except Exception as e:\n                                log_output(f\"Error saving manual config: {str(e)}\", \"error\")\n                else:\n                    st.error(\"Unable to load configuration file. Please ensure config.yaml exists.\")\n                    if st.button(\"\uD83D\uDD04 Retry Loading Config\", key=\"retry_config\"):\n                        try:\n                            st.session_state.helper.load_config()\n                            st.session_state.config_loaded = True\n                            log_output(\"Configuration loaded successfully\", \"success\")\n                            st.rerun()\n                        except Exception as e:\n                            log_output(f\"Error loading config: {str(e)}\", \"error\")\n\n                st.markdown('</div>', unsafe_allow_html=True)\n\n            elif operation == \"\uD83C\uDFAF Execute Full Training\":\n                st.markdown('''\n                <div class=\"config-panel\">\n                    <h3> \uD83C\uDFAF Full Model Training</h3>\n                </div>\n                ''', unsafe_allow_html=True)\n\n                # Training Progress Section\n                st.markdown(\"**Training Progress**\")\n                training_container = st.container()\n\n                if st.button(\"\uD83D\uDE80 Start Training\", key=\"train_btn\"):\n                    with training_container:\n                        # Create progress bar and status text\n                        progress_bar = st.progress(0)\n                        status_text = st.empty()\n                        execute_full_training(progress_bar, status_text)\n\n                st.markdown('</div>', unsafe_allow_html=True)\n\n            elif operation == \"\uD83C\uDFB2 Execute Prediction\":\n\n                st.markdown('''\n                <div class=\"config-panel\">\n                    <h3>\uD83C\uDFB2 Race Prediction</h3>\n                </div>\n                ''', unsafe_allow_html=True)\n\n                # Refresh races button\n                date=st.date_input(label=\"Date to sync\")\n                if st.button(\"\uD83D\uDD04 Refresh Races\", key=\"refresh_races\"):\n                    st.session_state.helper.sync_daily_races(date)\n\n                    # Get daily races\n                daily_races = st.session_state.helper.get_daily_races()\n\n                if daily_races:\n                    st.markdown(f\"{len(daily_races)}e races Today\")\n                # Create DataFrame for display\n                races_df = []\n                for race in daily_races:\n                    # Handle Race name with quinte indicator\n                    race_name = f\"R{race.get('prix', 'N/A')} - {race.get('prixnom', 'Unknown')}\"\n                    if race.get('quinte', 0) == 1:\n                        race_name = f\"\uD83C\uDF1F {race_name}\"\n\n                    status_indicators = []\n                    if race.get('has_processed_data', 0):\n                        status_indicators.append(\"✅ Processed\")\n                    if race.get('has_predictions', 0):\n                        status_indicators.append(\"\uD83D\uDD2E Predicted\")\n                    else:\n                        race[\"prediction_results\"]= json.dumps({\"predicted_arriv\": \"N/A\"})\n                    if race.get('has_results', 0):\n                        status_indicators.append(\"\uD83C\uDFC1 Results\")\n                    races_df.append({\n                        \"Date\": race['jour'],\n                        \"Race ID\": race['comp'],\n                        \"Track\": race['hippo'],\n                        \"Race\": race_name,\n                        \"Prediction\": json.loads(race[\"prediction_results\"]).get(\"predicted_arriv\"),\n                        \"Type\": race.get('typec', 'N/A'),\n                        \"Status\": \" | \".join(status_indicators) if status_indicators else \"⏳ Pending\"\n                    })\n                if races_df:\n                    # Display races table with selection\n                    edited_df = st.data_editor(\n                        races_df,\n                        column_config={\n                            \"Select\": st.column_config.CheckboxColumn(\n                                \"Select for Prediction\",\n                                help=\"Select races to predict\",\n                                default=False,\n                            )\n                        },\n                        disabled=[\"Date\", \"Race ID\", \"Track\", \"Race\", \"Prediction\", \"Type\", \"Status\"],\n                        hide_index=True,\n                        key=\"races_editor\"\n                    )\n                # Get races needing predictions\n                races_needing_prediction = st.session_state.helper.get_races_needing_prediction()\n                st.markdown(f\"**{len(races_needing_prediction)} races need predictions**\")\n                if st.button(\"\uD83D\uDD2E Predict All New Races\", key=\"predict_all\"):\n                    if races_needing_prediction:\n                        # Create progress bar and status text\n                        progress_bar = st.progress(0)\n                        status_text = st.empty()\n                        execute_predictions(None, progress_bar, status_text, force_reprediction=False)\n                        st.rerun()\n                    else:\n                        st.info(\"No races need predictions\")\n                if st.button(\" \uD83D\uDD01Force Reprediction All\"):\n                    progress_bar = st.progress(0)\n                    status_text = st.empty()\n                    execute_predictions(None, progress_bar, status_text, force_reprediction=True)\n                    st.rerun()\n\n                st.markdown('</div>', unsafe_allow_html=True)\n            elif operation == \"\uD83D\uDCC8 Execute Evaluation\":\n                st.markdown('''\n                <div class=\"config-panel\">\n                    <h3>\uD83D\uDCC8 Comprehensive Prediction Evaluation</h3>\n                </div>\n                ''', unsafe_allow_html=True)\n\n                st.info(\"Evaluate all races with both predictions and results using advanced analytics\")\n\n                left, right = st.columns(2)\n                with left:\n                   include_charts = st.checkbox(\"Include Visualization Charts\", value=True)\n                with right:\n                   include_recommendations = st.checkbox(\"Include Betting Recommendations\", value=True)\n\n                # Evaluation button\n                if st.button(\"\uD83D\uDCC8 Run Comprehensive Evaluation\", key=\"eval_btn\"):\n                # Create progress bar and status text\n                    progress_bar = st.progress(0)\n                    status_text = st.empty()\n                    execute_comprehensive_evaluation(progress_bar, status_text)\n                    st.rerun()\n\n            # Display results if available\n                if 'evaluation_results' in st.session_state and st.session_state.evaluation_results:\n                   results = st.session_state.evaluation_results\n                   if results['success']:\n                    st.success(\"✅ Evaluation completed successfully!\")\n\n                    # Display charts if requested\n                    if include_charts and 'chart_data' in results:\n                        display_evaluation_charts(results['chart_data'])\n\n                    # Raw metrics summary\n                    with st.expander(\"\uD83D\uDCCA Raw Metrics Summary\"):\n                        metrics = results['metrics']\n                        st.json({\n                        \"total_races\": metrics.total_races,\n                        \"races_evaluated\": metrics.races_evaluated,\n                        \"overall_winner_accuracy\": f\"{metrics.overall_winner_accuracy:.2%}\",\n                        \"overall_podium_accuracy\": f\"{metrics.overall_podium_accuracy:.2%}\",\n                        \"total_winning_bets\": metrics.total_winning_bets\n                        })\n\n                    # Detailed bet type wins\n                    with st.expander(\"\uD83C\uDFAF Detailed Bet Type Analysis\"):\n                        bet_wins = results['bet_type_wins']\n                        for bet_type, races in bet_wins.items():\n                            if bet_type:  # Only show bet types with wins\n                                st.markdown(f\"**{bet_type.replace('_', ' ').title()}:** {len(races)} winning races\")\n                                race_details = []\n                                for race in races:  # Show first 5 races\n                                    race_info = race.race_info\n                                    race_details.append(\n                                        f\"- {race_info['comp']}:{race_info['jour']} {race_info['hippo']} R{race_info['prix']}\"\n                                    )\n                                if race_details:\n                                    st.markdown(\"\\n\".join(race_details))\n                            else:\n                                st.error(f\"❌ Evaluation failed: {results['message']}\")\n\n                st.markdown('</div>', unsafe_allow_html=True)\n\n            elif operation == \"✨ AI Insight\":\n                st.markdown('''\n                <div class=\"config-panel\">\n                    <h3>\uD83E\uDD16 AI Betting Insights</h3>\n                </div>\n                ''', unsafe_allow_html=True)\n                \n                st.info(\"Get intelligent betting advice powered by AI analysis of your prediction results and market odds\")\n                \n                # AI Insight tabs\n                tab1, tab2, tab3 = st.tabs([\"\uD83D\uDCCA Daily Betting Advice\",\"\uD83C\uDF1F Quinte Race Advice\", \"\uD83C\uDFC7 Race-Specific Advice\"])\n                \n                with tab1:\n                    st.markdown(\"### \uD83D\uDCCA Daily Betting Performance Analysis\")\n                    st.markdown(\"Get comprehensive daily betting advice based on your model's recent performance\")\n                    \n                    # Configuration options\n                    col1, col2 = st.columns(2)\n                    with col1:\n                        lm_studio_url = st.text_input(\n                            \"LM Studio URL:\", \n                            value=\"http://localhost:1234\", \n                            help=\"Leave empty to use configuration default\"\n                        )\n                    with col2:\n                        verbose_ai = st.checkbox(\"Enable verbose AI output\", value=False)\n                    \n                    # Generate daily advice button\n                    if st.button(\"\uD83E\uDDE0 Generate Daily Betting Advice\", key=\"daily_ai_advice\"):\n                        with st.spinner(\"Analyzing your prediction results and generating advice...\"):\n                            # Use empty string if default URL is used\n                            url_param = lm_studio_url if lm_studio_url != \"http://localhost:1234\" else None\n                            \n                            result = st.session_state.helper.get_ai_betting_advice(\n                                lm_studio_url=url_param,\n                                verbose=verbose_ai\n                            )\n                            \n                            if result[\"success\"]:\n                                st.success(\"✅ AI betting advice generated successfully!\")\n                                \n                                # Display the AI advice\n                                st.markdown(\"### \uD83C\uDFAF AI Betting Recommendations\")\n                                st.markdown(result[\"ai_advice\"])\n                                \n                                # Show evaluation data used\n                                with st.expander(\"\uD83D\uDCCA Evaluation Data Used\"):\n                                    eval_data = result[\"evaluation_data\"]\n                                    \n                                    # Summary metrics\n                                    if 'summary_metrics' in eval_data:\n                                        st.markdown(\"**Performance Summary:**\")\n                                        metrics = eval_data['summary_metrics']\n                                        \n                                        col1, col2, col3 = st.columns(3)\n                                        with col1:\n                                            st.metric(\"Total Races\", metrics.get('total_races', 0))\n                                        with col2:\n                                            st.metric(\"Winner Accuracy\", f\"{metrics.get('winner_accuracy', 0):.1%}\")\n                                        with col3:\n                                            st.metric(\"Podium Accuracy\", f\"{metrics.get('podium_accuracy', 0):.1%}\")\n                                    \n                                    # Bet performance\n                                    if 'pmu_summary' in eval_data:\n                                        st.markdown(\"**Bet Type Performance:**\")\n                                        pmu_summary = eval_data['pmu_summary']\n                                        \n                                        bet_df = []\n                                        for bet_type, rate in pmu_summary.items():\n                                            if rate > 0:\n                                                bet_df.append({\n                                                    'Bet Type': bet_type.replace('_rate', '').replace('_', ' ').title(),\n                                                    'Win Rate': f\"{rate:.1%}\"\n                                                })\n                                        \n                                        if bet_df:\n                                            st.dataframe(pd.DataFrame(bet_df), hide_index=True)\n                                \n                            else:\n                                st.error(f\"❌ Failed to generate AI advice: {result['message']}\")\n                                if 'error' in result:\n                                    st.error(f\"Error details: {result['error']}\")\n                \n                with tab2:\n                    st.markdown(\"### \uD83C\uDF1F Quinté+ Specialized Betting Strategy\")\n                    st.markdown(\"Get **3 refined betting recommendations** specifically optimized for quinté races\")\n                    \n                    # Info box about quinte focus\n                    st.info(\"\uD83C\uDFAF **Quinté+ Focus**: This analysis specifically targets quinté races and provides 3 structured betting recommendations: Conservative, Balanced, and Aggressive strategies based on historical quinte performance.\")\n                    \n                    # Configuration options\n                    col1, col2 = st.columns(2)\n                    with col1:\n                        quinte_lm_studio_url = st.text_input(\n                            \"LM Studio URL:\", \n                            value=\"http://localhost:1234\", \n                            help=\"Leave empty to use configuration default\",\n                            key=\"quinte_lm_url\"\n                        )\n                    with col2:\n                        quinte_verbose_ai = st.checkbox(\"Enable verbose AI output\", value=False, key=\"quinte_verbose\")\n                    \n                    # Generate quinte advice button\n                    if st.button(\"\uD83C\uDF1F Generate Quinté+ Betting Strategy\", key=\"quinte_ai_advice\"):\n                        with st.spinner(\"Analyzing quinté performance and generating 3 refined betting recommendations...\"):\n                            # Use empty string if default URL is used\n                            url_param = quinte_lm_studio_url if quinte_lm_studio_url != \"http://localhost:1234\" else None\n                            \n                            result = st.session_state.helper.get_ai_quinte_advice(\n                                lm_studio_url=url_param,\n                                verbose=quinte_verbose_ai\n                            )\n                            \n                            if result[\"success\"]:\n                                st.success(\"✅ Quinté+ betting strategy generated successfully!\")\n                                \n                                # Display the AI advice\n                                st.markdown(\"### \uD83C\uDFAF 3 Refined Quinté+ Betting Recommendations\")\n                                st.markdown(result[\"ai_advice\"])\n                                \n                                # Show evaluation data used\n                                with st.expander(\"\uD83D\uDCCA Quinté+ Performance Data Used\"):\n                                    eval_data = result[\"evaluation_data\"]\n                                    \n                                    # Summary metrics\n                                    if 'summary_metrics' in eval_data:\n                                        st.markdown(\"**Overall Performance Summary:**\")\n                                        metrics = eval_data['summary_metrics']\n                                        \n                                        col1, col2, col3 = st.columns(3)\n                                        with col1:\n                                            st.metric(\"Total Races\", metrics.get('total_races', 0))\n                                        with col2:\n                                            st.metric(\"Winner Accuracy\", f\"{metrics.get('winner_accuracy', 0):.1%}\")\n                                        with col3:\n                                            st.metric(\"Podium Accuracy\", f\"{metrics.get('podium_accuracy', 0):.1%}\")\n                                    \n                                    # Quinte specific analysis\n                                    if 'quinte_analysis' in eval_data:\n                                        st.markdown(\"**Quinté+ Specific Analysis:**\")\n                                        quinte_data = eval_data['quinte_analysis']\n                                        \n                                        # Display key quinte metrics\n                                        if 'total_quinte_races' in quinte_data:\n                                            st.metric(\"Total Quinté+ Races\", quinte_data['total_quinte_races'])\n                                        \n                                        # Show betting scenarios performance\n                                        if 'betting_scenarios' in quinte_data:\n                                            st.markdown(\"**Horse Selection Strategies:**\")\n                                            scenarios = quinte_data['betting_scenarios']\n                                            \n                                            scenario_df = []\n                                            for scenario, data in scenarios.items():\n                                                scenario_df.append({\n                                                    'Strategy': scenario.replace('_', ' ').title(),\n                                                    'Wins': data.get('wins', 0),\n                                                    'Total': data.get('total', 0),\n                                                    'Win Rate': f\"{data.get('win_rate', 0):.1%}\"\n                                                })\n                                            \n                                            if scenario_df:\n                                                st.dataframe(pd.DataFrame(scenario_df), hide_index=True)\n                                    \n                                    # PMU summary focused on quinte\n                                    if 'pmu_summary' in eval_data:\n                                        st.markdown(\"**Quinté+ Bet Type Performance:**\")\n                                        pmu_summary = eval_data['pmu_summary']\n                                        \n                                        quinte_bet_df = []\n                                        quinte_bets = [\n                                            ('quinte_exact_rate', 'Quinté+ Exact'),\n                                            ('quinte_desordre_rate', 'Quinté+ Désordre'),\n                                            ('bonus4_rate', 'Bonus 4'),\n                                            ('bonus3_rate', 'Bonus 3'),\n                                            ('multi4_rate', 'Multi 4')\n                                        ]\n                                        \n                                        for bet_key, bet_name in quinte_bets:\n                                            if bet_key in pmu_summary and pmu_summary[bet_key] > 0:\n                                                quinte_bet_df.append({\n                                                    'Bet Type': bet_name,\n                                                    'Win Rate': f\"{pmu_summary[bet_key]:.1%}\"\n                                                })\n                                        \n                                        if quinte_bet_df:\n                                            st.dataframe(pd.DataFrame(quinte_bet_df), hide_index=True)\n                                        else:\n                                            st.info(\"No quinté bet wins recorded in current data\")\n                                \n                            else:\n                                st.error(f\"❌ Failed to generate quinté betting strategy: {result['message']}\")\n                                if 'error' in result:\n                                    st.error(f\"Error details: {result['error']}\")\n                \n                with tab3:\n                    st.markdown(\"### \uD83C\uDFC7 Race-Specific AI Analysis\")\n                    st.markdown(\"Get detailed AI advice for specific races including odds analysis and betting recommendations\")\n                    \n                    # Get available races\n                    daily_races = st.session_state.helper.get_daily_races()\n                    \n                    if daily_races:\n                        # Filter races with predictions\n                        races_with_predictions = [race for race in daily_races if race.get('has_predictions', 0) == 1]\n                        \n                        if races_with_predictions:\n                            # Race selection\n                            race_options = []\n                            for race in races_with_predictions:\n                                race_name = f\"{race['hippo']} - R{race.get('prix', 'N/A')} - {race.get('prixnom', 'Unknown')}\"\n                                if race.get('quinte', 0) == 1:\n                                    race_name = f\"\uD83C\uDF1F {race_name}\"\n                                race_options.append(race_name)\n                            \n                            selected_race_idx = st.selectbox(\n                                \"Select a race for AI analysis:\",\n                                range(len(race_options)),\n                                format_func=lambda x: race_options[x]\n                            )\n                            \n                            selected_race = races_with_predictions[selected_race_idx]\n                            \n                            # Configuration for race analysis\n                            col1, col2 = st.columns(2)\n                            with col1:\n                                race_lm_studio_url = st.text_input(\n                                    \"LM Studio URL:\", \n                                    value=\"http://localhost:1234\", \n                                    help=\"Leave empty to use configuration default\",\n                                    key=\"race_lm_url\"\n                                )\n                            with col2:\n                                race_verbose_ai = st.checkbox(\"Enable verbose AI output\", value=False, key=\"race_verbose\")\n                            \n                            # Generate race advice button\n                            if st.button(\"\uD83E\uDDE0 Generate Race Analysis\", key=\"race_ai_advice\"):\n                                with st.spinner(f\"Analyzing race {selected_race['comp']} and generating advice...\"):\n                                    # Use empty string if default URL is used\n                                    url_param = race_lm_studio_url if race_lm_studio_url != \"http://localhost:1234\" else None\n                                    \n                                    result = st.session_state.helper.get_ai_race_advice(\n                                        race_comp=selected_race['comp'],\n                                        lm_studio_url=url_param,\n                                        verbose=race_verbose_ai\n                                    )\n                                    \n                                    if result[\"success\"]:\n                                        st.success(f\"✅ AI race analysis generated for {selected_race['comp']}!\")\n                                        \n                                        # Display the AI advice\n                                        st.markdown(\"### \uD83C\uDFAF AI Race Analysis & Recommendations\")\n                                        st.markdown(result[\"ai_advice\"])\n                                        \n                                        # Show race data and predictions used\n                                        with st.expander(\"\uD83D\uDCCA Race Data & Predictions Used\"):\n                                            race_data = result[\"race_data\"]\n                                            predictions = result[\"predictions\"]\n                                            \n                                            # Race information\n                                            st.markdown(\"**Race Information:**\")\n                                            col1, col2, col3 = st.columns(3)\n                                            with col1:\n                                                st.metric(\"Date\", race_data.get('jour', 'N/A'))\n                                            with col2:\n                                                st.metric(\"Track\", race_data.get('hippo', 'N/A'))\n                                            with col3:\n                                                st.metric(\"Race\", f\"R{race_data.get('prix', 'N/A')}\")\n                                            \n                                            # Predictions\n                                            if predictions and 'predictions' in predictions:\n                                                st.markdown(\"**Top Predictions:**\")\n                                                pred_data = predictions['predictions']\n                                                \n                                                # Create DataFrame from predictions\n                                                pred_df = []\n                                                for pred in pred_data[:8]:  # Show top 8\n                                                    pred_df.append({\n                                                        'Horse': pred.get('numero', 'N/A'),\n                                                        'Predicted Rank': pred.get('predicted_rank', pred.get('predicted_position', 'N/A')),\n                                                        'Confidence': f\"{pred.get('confidence', pred.get('predicted_prob', 0)):.2%}\" if isinstance(pred.get('confidence', pred.get('predicted_prob', 0)), (int, float)) else 'N/A'\n                                                    })\n                                                \n                                                if pred_df:\n                                                    st.dataframe(pd.DataFrame(pred_df), hide_index=True)\n                                    \n                                    else:\n                                        st.error(f\"❌ Failed to generate race analysis: {result['message']}\")\n                                        if 'error' in result:\n                                            st.error(f\"Error details: {result['error']}\")\n                        else:\n                            st.warning(\"No races with predictions found. Please run predictions first.\")\n                            st.info(\"Go to '\uD83C\uDFB2 Execute Prediction' to generate predictions for today's races.\")\n                    else:\n                        st.warning(\"No races available for analysis.\")\n                        st.info(\"Go to '\uD83C\uDFB2 Execute Prediction' to sync and predict today's races.\")\n                \n                st.markdown('</div>', unsafe_allow_html=True)\n\n            elif operation == \"\uD83D\uDD04 Incremental Training\":\n\n                st.markdown('<div class=\"config-panel\">', unsafe_allow_html=True)\n\n                st.markdown(\"### \uD83D\uDD04 Incremental Training & Regression Enhancement\")\n\n                st.info(\"Process completed races with predictions and results to improve model performance\")\n\n                # Training parameters\n\n                left, right = st.columns(2)\n\n                with left:\n                    date_from = st.date_input(\n\n                        \"Start Date:\",\n\n                        value=(datetime.now() - timedelta(days=30)).date(),\n\n                        key=\"incr_date_from\"\n\n                    )\n\n                    update_model = st.checkbox(\n\n                        \"Update Base Model\",\n\n                        value=True,\n\n                        help=\"Whether to update the base model with new data\"\n\n                    )\n\n                with right:\n                    date_to = st.date_input(\n\n                        \"End Date:\",\n\n                        value=datetime.now().date(),\n\n                        key=\"incr_date_to\"\n\n                    )\n\n                    create_enhanced = st.checkbox(\n\n                        \"Create Enhanced Model\",\n\n                        value=True,\n\n                        help=\"Create enhanced model with error correction\"\n\n                    )\n\n                # Advanced options\n\n                with st.expander(\"\uD83D\uDD27 Advanced Options\"):\n                    limit_races = st.number_input(\n\n                        \"Limit Races (0 = no limit):\",\n\n                        min_value=0,\n\n                        value=0,\n\n                        help=\"Maximum number of races to process\"\n\n                    )\n\n                    archive_after = st.checkbox(\n\n                        \"Archive Races After Training\",\n\n                        value=True,\n\n                        help=\"Move processed races from daily_race to historical_races\"\n\n                    )\n\n                # Show current state\n\n                races_with_results = st.session_state.helper.get_races_with_results(\n\n                    date_from.strftime('%Y-%m-%d'),\n\n                    date_to.strftime('%Y-%m-%d')\n\n                )\n\n                if races_with_results:\n\n                    st.success(f\"Found {len(races_with_results)} races with predictions and results\")\n\n                    # Show sample of races\n\n                    with st.expander(\"\uD83D\uDCCB Races Ready for Training\"):\n\n                        sample_df = pd.DataFrame(races_with_results[:10])  # Show first 10\n\n                        if not sample_df.empty:\n\n                            display_cols = ['comp', 'jour', 'hippo', 'prix', 'partant']\n\n                            available_cols = [col for col in display_cols if col in sample_df.columns]\n\n                            st.dataframe(sample_df[available_cols], hide_index=True)\n\n                            if len(races_with_results) > 10:\n                                st.info(f\"... and {len(races_with_results) - 10} more races\")\n\n                else:\n\n                    st.warning(\"No races with both predictions and results found for the selected date range\")\n\n                # Training execution\n\n                if st.button(\"\uD83D\uDE80 Start Incremental Training\", key=\"incr_btn\"):\n\n                    if races_with_results:\n\n                        # Create progress bar and status text\n\n                        progress_bar = st.progress(0)\n\n                        status_text = st.empty()\n\n                        execute_incremental_training(\n\n                            date_from.strftime('%Y-%m-%d'),\n\n                            date_to.strftime('%Y-%m-%d'),\n\n                            limit_races if limit_races > 0 else None,\n\n                            update_model,\n\n                            create_enhanced,\n\n                            archive_after,\n\n                            progress_bar,\n\n                            status_text\n\n                        )\n\n                        # Display results if stored in session state\n\n                        if 'incremental_results' in st.session_state:\n                            results = st.session_state.incremental_results\n\n                            if results.get('success'):\n                                st.success(\"✅ Incremental training completed!\")\n\n                                # Display training metrics\n                                training_results = results.get('training_results', {})\n\n                                if training_results:\n                                    st.markdown(\"### \uD83D\uDCCA Training Results\")\n\n                                    # Performance metrics\n                                    if 'performance_analysis' in training_results:\n                                        perf = training_results['performance_analysis']\n\n                                        left, center, right = st.columns(3)\n                                        with left:\n                                            st.metric(\"Sample Size\", perf.get('sample_size', 0))\n                                        with center:\n                                            st.metric(\"MAE\", f\"{perf.get('overall_mae', 0):.4f}\")\n                                        with right:\n                                            st.metric(\"RMSE\", f\"{perf.get('overall_rmse', 0):.4f}\")\n\n                                    # RF Model improvement metrics\n                                    if 'rf_training' in training_results:\n                                        rf_results = training_results['rf_training']\n\n                                        if rf_results.get('status') == 'success':\n                                            improvement = rf_results.get('improvement', {})\n                                            st.markdown(\"### \uD83C\uDFAF RF Model Improvement\")\n\n                                            left, right = st.columns(2)\n                                            with left:\n                                                mae_improvement = improvement.get('mae_improvement_pct', 0)\n                                                st.metric(\n                                                    \"RF MAE Improvement\",\n                                                    f\"{mae_improvement:.2f}%\",\n                                                    delta=f\"{mae_improvement:.2f}%\"\n                                                )\n                                            with right:\n                                                rmse_improvement = improvement.get('rmse_improvement_pct', 0)\n                                                st.metric(\n                                                    \"RF RMSE Improvement\",\n                                                    f\"{rmse_improvement:.2f}%\",\n                                                    delta=f\"{rmse_improvement:.2f}%\"\n                                                )\n\n                                            # Significance indicator\n                                            if improvement.get('significant', False):\n                                                st.success(\"\uD83C\uDF89 RF model shows significant improvement!\")\n                                            else:\n                                                st.info(\"ℹ\uFE0F RF improvement below threshold.\")\n\n                                    # LSTM Model improvement metrics\n                                    if 'lstm_training' in training_results:\n                                        lstm_results = training_results['lstm_training']\n\n                                        if lstm_results.get('status') == 'success':\n                                            lstm_improvement = lstm_results.get('improvement', {})\n                                            st.markdown(\"### \uD83E\uDDE0 LSTM Model Improvement\")\n\n                                            left, right = st.columns(2)\n                                            with left:\n                                                lstm_mae_improvement = lstm_improvement.get('mae_improvement_pct', 0)\n                                                st.metric(\n                                                    \"LSTM MAE Improvement\",\n                                                    f\"{lstm_mae_improvement:.2f}%\",\n                                                    delta=f\"{lstm_mae_improvement:.2f}%\"\n                                                )\n                                            with right:\n                                                lstm_rmse_improvement = lstm_improvement.get('rmse_improvement_pct', 0)\n                                                st.metric(\n                                                    \"LSTM RMSE Improvement\",\n                                                    f\"{lstm_rmse_improvement:.2f}%\",\n                                                    delta=f\"{lstm_rmse_improvement:.2f}%\"\n                                                )\n\n                                            if lstm_improvement.get('significant', False):\n                                                st.success(\"\uD83C\uDF89 LSTM model shows significant improvement!\")\n                                            else:\n                                                st.info(\"ℹ\uFE0F LSTM improvement below threshold.\")\n\n                                        elif lstm_results.get('status') == 'skipped':\n                                            st.warning(\"⚠\uFE0F LSTM training was skipped\")\n                                            if lstm_results.get('message'):\n                                                st.info(f\"Reason: {lstm_results['message']}\")\n\n                                    # Model saving results\n                                    if 'model_saved' in training_results:\n                                        model_saved = training_results['model_saved']\n\n                                        if model_saved.get('status') == 'success':\n                                            st.markdown(\"### \uD83D\uDCBE Model Saving\")\n                                            version = model_saved.get('version', 'unknown')\n                                            st.success(f\"✅ New model saved: **{version}**\")\n\n                                            # Show which models were updated\n                                            models_updated = model_saved.get('models_updated', {})\n                                            model_sources = model_saved.get('model_sources', {})\n\n                                            left, right = st.columns(2)\n                                            with left:\n                                                if models_updated.get('rf', False):\n                                                    st.info(\"\uD83D\uDD04 RF model: Retrained\")\n                                                else:\n                                                    st.info(\"\uD83D\uDCCB RF model: Copied from base\")\n\n                                            with right:\n                                                if models_updated.get('lstm', False):\n                                                    st.info(\"\uD83D\uDD04 LSTM model: Retrained\")\n                                                else:\n                                                    st.info(\"\uD83D\uDCCB LSTM model: Copied from base\")\n\n                                        else:\n                                            st.warning(\"⚠\uFE0F Models were not saved\")\n                                            if model_saved.get('reason'):\n                                                st.info(f\"Reason: {model_saved['reason']}\")\n\n                                    # Archive results\n                                    if 'races_archived' in training_results:\n                                        archive = training_results['races_archived']\n\n                                        if archive.get('status') == 'success':\n                                            archived_count = archive.get('successful', 0)\n                                            st.success(f\"\uD83D\uDCC1 Archived {archived_count} races to historical data\")\n                                        elif archive.get('status') == 'skipped':\n                                            st.info(\"\uD83D\uDCC1 Race archiving was skipped\")\n                                        else:\n                                            st.warning(\"⚠\uFE0F Race archiving failed\")\n\n                                    # Execution summary\n                                    execution_time = training_results.get('execution_time', 0)\n                                    races_processed = training_results.get('races_processed', 0)\n                                    training_samples = training_results.get('training_samples', 0)\n\n                                    st.markdown(\"### ⏱\uFE0F Execution Summary\")\n                                    left, center, right = st.columns(3)\n                                    with left:\n                                        st.metric(\"Races Processed\", races_processed)\n                                    with center:\n                                        st.metric(\"Training Samples\", training_samples)\n                                    with right:\n                                        st.metric(\"Execution Time\", f\"{execution_time:.1f}s\")\n\n                            else:\n                                st.error(f\"❌ Training failed: {results.get('message', 'Unknown error')}\")\n\n    with col2:\n        # Status and output panel\n        st.markdown('''\n                        <div class=\"output-panel\">\n                            <h3> \uD83D\uDCCB System Status</h3>\n                            <!-- Other content here -->\n                        </div>\n                        ''', unsafe_allow_html=True)\n\n\n        # Load config if not already loaded for status\n        if not st.session_state.config_loaded:\n            load_config()\n\n        # System status indicators\n        last_training, model_version = st.session_state.helper.get_last_training_info()\n        col_status1, col_status2 = st.columns(2)\n        with col_status1:\n            st.metric(\"Active DB\", st.session_state.helper.get_active_db())\n            st.metric(\"Last Training\", last_training)\n        with col_status2:\n            st.metric(\"Model Version\", model_version)\n\n        st.markdown('</div>', unsafe_allow_html=True)\n\n        # Output logs\n        if st.button(\"\uD83D\uDDD1\uFE0F Clear Logs\"):\n            clear_logs()\n\n        display_logs()\n\n\nif __name__ == \"__main__\":\n    main()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/UI/UIApp.py b/UI/UIApp.py
--- a/UI/UIApp.py	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
+++ b/UI/UIApp.py	(date 1759478317203)
@@ -561,6 +561,7 @@
             "🎲 Execute Prediction",
             "✨ AI Insight",
             "📈 Execute Evaluation",
+            "⚖️ Model Weight Analysis",
             "🔄 Incremental Training",
             "🎯 Execute Full Training",
             "🔄 MySQL ↔ SQLite Sync",
@@ -832,16 +833,25 @@
                         status_indicators.append("✅ Processed")
                     if race.get('has_predictions', 0):
                         status_indicators.append("🔮 Predicted")
-                    else:
-                        race["prediction_results"]= json.dumps({"predicted_arriv": "N/A"})
                     if race.get('has_results', 0):
                         status_indicators.append("🏁 Results")
+
+                    # Handle prediction results safely
+                    import json
+                    predicted_arriv = "N/A"
+                    if race.get("prediction_results"):
+                        try:
+                            pred_data = json.loads(race["prediction_results"])
+                            predicted_arriv = pred_data.get("predicted_arriv", "N/A")
+                        except (json.JSONDecodeError, TypeError):
+                            predicted_arriv = "N/A"
+
                     races_df.append({
                         "Date": race['jour'],
                         "Race ID": race['comp'],
                         "Track": race['hippo'],
                         "Race": race_name,
-                        "Prediction": json.loads(race["prediction_results"]).get("predicted_arriv"),
+                        "Prediction": predicted_arriv,
                         "Type": race.get('typec', 'N/A'),
                         "Status": " | ".join(status_indicators) if status_indicators else "⏳ Pending"
                     })
@@ -1238,6 +1248,220 @@
                         st.warning("No races available for analysis.")
                         st.info("Go to '🎲 Execute Prediction' to sync and predict today's races.")
                 
+                st.markdown('</div>', unsafe_allow_html=True)
+
+            elif operation == "⚖️ Model Weight Analysis":
+                st.markdown('''
+                <div class="config-panel">
+                    <h3>⚖️ Automated Weight & Pattern Analysis</h3>
+                </div>
+                ''', unsafe_allow_html=True)
+
+                st.info("🤖 Automated analysis: Tests all RF/TabNet weight combinations (0.0-1.0 by 0.1), finds optimal weights, and detects patterns based on race features")
+
+                # Initialize session state for analysis results
+                if 'weight_patterns' not in st.session_state:
+                    st.session_state.weight_patterns = None
+
+                # Simple Configuration
+                st.markdown("### ⚙️ Configuration")
+
+                left, right = st.columns(2)
+
+                with left:
+                    date_from_weight = st.date_input(
+                        "Start Date:",
+                        value=(datetime.now() - timedelta(days=90)).date(),
+                        key="weight_date_from",
+                        help="Recommended: 30-90 days for reliable patterns"
+                    )
+
+                with right:
+                    date_to_weight = st.date_input(
+                        "End Date:",
+                        value=datetime.now().date(),
+                        key="weight_date_to"
+                    )
+
+                # Single-click automated analysis
+                if st.button("🚀 Run Automated Analysis", key="run_auto_analysis", help="Tests all weights and detects patterns automatically"):
+                    with st.spinner("📊 Loading race data..."):
+                        # Load data
+                        data_result = st.session_state.helper.load_weight_analysis_data(
+                            date_from=date_from_weight.strftime('%Y-%m-%d'),
+                            date_to=date_to_weight.strftime('%Y-%m-%d'),
+                            race_filters=None
+                        )
+
+                        if data_result['success']:
+                            log_output(data_result['message'], "success")
+
+                            # Run automated pattern detection
+                            with st.spinner("🔍 Testing all weight combinations (0.0-1.0 by 0.1) and detecting patterns..."):
+                                pattern_result = st.session_state.helper.detect_weight_patterns(
+                                    data_df=data_result['data'].copy(),
+                                    weight_step=0.1
+                                )
+
+                                if pattern_result['success']:
+                                    st.session_state.weight_patterns = pattern_result
+                                    log_output(pattern_result['message'], "success")
+                                else:
+                                    log_output(pattern_result['message'], "error")
+                        else:
+                            log_output(data_result['message'], "error")
+
+                        st.rerun()
+
+                # Display Results
+                if st.session_state.weight_patterns is not None:
+                    patterns = st.session_state.weight_patterns['patterns']
+
+                    st.markdown("### 📊 Analysis Results")
+
+                    # Summary insights
+                    st.markdown("#### 💡 Key Findings")
+                    for insight in patterns['summary']:
+                        if insight['type'] == 'no_patterns':
+                            st.success(f"✅ {insight['message']}")
+                        elif insight['type'] == 'patterns_found':
+                            st.warning(f"⚠️ {insight['message']}")
+                        else:
+                            st.info(f"📌 {insight['message']}")
+
+                    # Overall Optimal Weights
+                    overall = patterns['overall_best']
+
+                    st.markdown("#### 🎯 Overall Best Weights")
+                    col1, col2, col3, col4, col5 = st.columns(5)
+                    with col1:
+                        st.metric("RF Weight", f"{overall['rf_weight']:.1f}")
+                    with col2:
+                        st.metric("TabNet Weight", f"{overall['tabnet_weight']:.1f}")
+                    with col3:
+                        st.metric("Winner Accuracy", f"{overall['winner_accuracy']*100:.1f}%")
+                    with col4:
+                        st.metric("Podium Accuracy", f"{overall['podium_accuracy']*100:.1f}%")
+                    with col5:
+                        st.metric("MAE", f"{overall['mae']:.2f}")
+
+                    # Pattern-specific recommendations
+                    st.markdown("#### 🔍 Detected Patterns Requiring Custom Weights")
+
+                    # Race Type Patterns
+                    if patterns['by_race_type']:
+                        st.markdown("##### 🏇 Race Type Patterns")
+
+                        for pattern in patterns['by_race_type']:
+                            with st.expander(f"**{pattern['typec']}** - Custom weights recommended"):
+                                pcol1, pcol2, pcol3, pcol4 = st.columns(4)
+
+                                with pcol1:
+                                    st.metric("Optimal RF", f"{pattern['optimal_rf_weight']:.1f}")
+                                with pcol2:
+                                    st.metric("Optimal TabNet", f"{pattern['optimal_tabnet_weight']:.1f}")
+                                with pcol3:
+                                    st.metric("Winner Accuracy", f"{pattern['winner_accuracy']*100:.1f}%")
+                                    if pattern['improvement_vs_overall'] > 0:
+                                        st.success(f"+{pattern['improvement_vs_overall']*100:.1f}% vs overall")
+                                with pcol4:
+                                    st.metric("Races", pattern['total_races'])
+
+                                st.info(f"💡 **Recommendation:** {pattern['recommendation']}")
+                    else:
+                        st.success("✅ No significant race type patterns detected - overall weights work well")
+
+                    # Distance Range Patterns
+                    if patterns['by_distance_range']:
+                        st.markdown("##### 📏 Distance Range Patterns")
+
+                        for pattern in patterns['by_distance_range']:
+                            with st.expander(f"**{pattern['distance_range']}** - Custom weights recommended"):
+                                pcol1, pcol2, pcol3, pcol4 = st.columns(4)
+
+                                with pcol1:
+                                    st.metric("Optimal RF", f"{pattern['optimal_rf_weight']:.1f}")
+                                with pcol2:
+                                    st.metric("Optimal TabNet", f"{pattern['optimal_tabnet_weight']:.1f}")
+                                with pcol3:
+                                    st.metric("Winner Accuracy", f"{pattern['winner_accuracy']*100:.1f}%")
+                                    if pattern['improvement_vs_overall'] > 0:
+                                        st.success(f"+{pattern['improvement_vs_overall']*100:.1f}% vs overall")
+                                with pcol4:
+                                    st.metric("Races", pattern['total_races'])
+
+                                st.info(f"💡 **Recommendation:** {pattern['recommendation']}")
+                    else:
+                        st.success("✅ No significant distance patterns detected - overall weights work well")
+
+                    # Field Size Patterns
+                    if patterns['by_field_size']:
+                        st.markdown("##### 👥 Field Size Patterns")
+
+                        for pattern in patterns['by_field_size']:
+                            with st.expander(f"**{pattern['field_size']}** - Custom weights recommended"):
+                                pcol1, pcol2, pcol3, pcol4 = st.columns(4)
+
+                                with pcol1:
+                                    st.metric("Optimal RF", f"{pattern['optimal_rf_weight']:.1f}")
+                                with pcol2:
+                                    st.metric("Optimal TabNet", f"{pattern['optimal_tabnet_weight']:.1f}")
+                                with pcol3:
+                                    st.metric("Winner Accuracy", f"{pattern['winner_accuracy']*100:.1f}%")
+                                    if pattern['improvement_vs_overall'] > 0:
+                                        st.success(f"+{pattern['improvement_vs_overall']*100:.1f}% vs overall")
+                                with pcol4:
+                                    st.metric("Races", pattern['total_races'])
+
+                                st.info(f"💡 **Recommendation:** {pattern['recommendation']}")
+                    else:
+                        st.success("✅ No significant field size patterns detected - overall weights work well")
+
+                    # Weight performance visualization
+                    with st.expander("📈 View All Weight Combinations Performance"):
+                        all_results_df = pd.DataFrame(st.session_state.weight_patterns['all_weight_results'])
+
+                        # Winner accuracy line chart
+                        fig_winner = px.line(
+                            all_results_df,
+                            x='rf_weight',
+                            y='winner_accuracy',
+                            title='Winner Accuracy vs RF Weight (all tested combinations)',
+                            markers=True
+                        )
+                        fig_winner.update_yaxes(title='Winner Accuracy', tickformat='.1%')
+                        fig_winner.update_xaxes(title='RF Weight')
+                        fig_winner.update_traces(line_color='#244855', marker_color='#E64833')
+                        fig_winner.update_layout(
+                            height=400,
+                            paper_bgcolor='rgba(0,0,0,0)',
+                            plot_bgcolor='rgba(0,0,0,0)'
+                        )
+                        st.plotly_chart(fig_winner, use_container_width=True)
+
+                        # Data table
+                        st.dataframe(all_results_df, hide_index=True, use_container_width=True)
+
+                    # Export options
+                    with st.expander("💾 Export Pattern Results"):
+                        # Create comprehensive export
+                        export_data = {
+                            'overall_best': patterns['overall_best'],
+                            'race_type_patterns': patterns['by_race_type'],
+                            'distance_patterns': patterns['by_distance_range'],
+                            'field_size_patterns': patterns['by_field_size']
+                        }
+
+                        import json
+                        json_str = json.dumps(export_data, indent=2)
+
+                        st.download_button(
+                            label="📥 Download Pattern Analysis (JSON)",
+                            data=json_str,
+                            file_name=f"weight_pattern_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
+                            mime="application/json"
+                        )
+
                 st.markdown('</div>', unsafe_allow_html=True)
 
             elif operation == "🔄 Incremental Training":
Index: config.yaml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>base:\n  active_db: 2years\n  rootdir: /Users/mattg0/Docs/HorseAIv2/\nblend:\n  description: Optimal blend weights for position prediction accuracy\n  lstm_weight: 0.1\n  optimal_mae: 11.78\n  rf_weight: 0.8\n  tabnet_weight: 0.1\ncache:\n  base_path: cache\n  types:\n    features: features.parquet\n    historical_data: historical_data.parquet\n    models: models.parquet\n    predictions: predictions.parquet\n    processed_data: processed_data.parquet\n  use_cache: true\ndatabases:\n- description: Full historical database\n  name: full\n  path: data/hippique.db\n  type: sqlite\n- description: Last 2 years of data\n  name: 2years\n  path: data/hippique2.db\n  type: sqlite\n- description: Last 5 years of data\n  name: 5years\n  path: data/hippique5.db\n  type: sqlite\n- description: Dev DB\n  name: dev\n  path: data/test_lite.db\n  type: sqlite\n- dbname: pturf2024\n  description: MySQL datasource\n  host: localhost\n  name: mysql\n  password: welcome123\n  type: mysql\n  user: turfai\ndataset:\n  random_state: 42\n  test_size: 0.2\n  val_size: 0.1\nfeatures:\n  clean_after_embedding: true\n  default_task_type: regression\n  embedding_dim: 8\n  features_dir: ./data/feature_store\n  keep_identifiers: false\nllm_url:\n  local: http://localhost:1234\nlstm:\n  sequence_length: 5\n  sequential_features:\n  - final_position\n  - cotedirect\n  - dist\n  - horse_emb_0\n  - horse_emb_1\n  - horse_emb_2\n  - jockey_emb_0\n  - jockey_emb_1\n  - jockey_emb_2\n  - che_global_avg_pos\n  - che_global_recent_perf\n  - che_global_consistency\n  - che_global_pct_top3\n  static_features:\n  - age\n  - temperature\n  - natpis\n  - typec\n  - meteo\n  - corde\n  - couple_emb_0\n  - couple_emb_1\n  - couple_emb_2\n  - course_emb_0\n  - course_emb_1\n  - course_emb_2\n  step_size: 1\nmodels:\n  latest_model: 2025-07-25/2years_165819\n  model_dir: ./models\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/config.yaml b/config.yaml
--- a/config.yaml	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
+++ b/config.yaml	(date 1759478048634)
@@ -83,5 +83,7 @@
   - course_emb_2
   step_size: 1
 models:
-  latest_model: 2025-07-25/2years_165819
-  model_dir: ./models
+  latest_models:
+    rf: 2025-10-01/2years_154345
+    tabnet: 2025-10-01/2years_154355
+  model_dir: ./models
\ No newline at end of file
Index: lstmdebug.py
===================================================================
diff --git a/lstmdebug.py b/lstmdebug.py
deleted file mode 100644
--- a/lstmdebug.py	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
+++ /dev/null	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
@@ -1,400 +0,0 @@
-#!/usr/bin/env python
-# lstm_debug_with_real_data.py - Debug LSTM model with real race data
-
-import os
-import sys
-import numpy as np
-import pandas as pd
-from pathlib import Path
-import tensorflow as tf
-from tensorflow.keras.models import load_model
-import joblib
-import sqlite3
-from typing import Optional, Tuple, Dict, List
-
-# Add the project root to path to ensure imports work
-import os
-
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
-
-# Import required project modules
-from utils.env_setup import AppConfig
-from core.orchestrators.embedding_feature import FeatureEmbeddingOrchestrator
-from core.connectors.api_daily_sync import RaceFetcher
-
-# ===== CONFIGURATION =====
-MODEL_PATH = "models/2years/hybrid/2years_full_v20250409/hybrid_lstm_model.keras"
-FEATURE_CONFIG_PATH = "models/2years/hybrid/2years_full_v20250409/hybrid_feature_engineer.joblib"
-COMP_ID = "1576910"  # The specific race to analyze
-DB_NAME = "2years"  # Database to use
-
-
-def analyze_model(model_path):
-    """Analyze a Keras model to identify input layer requirements"""
-    print(f"\n===== ANALYZING MODEL: {model_path} =====")
-
-    # Load the model
-    try:
-        model = load_model(model_path)
-        print("Model loaded successfully")
-        model.summary()
-
-        # Extract input shapes directly from model.inputs
-        print("\n===== INPUT SHAPE ANALYSIS =====")
-        for i, input_tensor in enumerate(model.inputs):
-            # Fix: handle the shape attribute properly
-            shape = input_tensor.shape
-            # Convert to list if needed
-            shape_list = [dim if dim is not None else None for dim in shape]
-
-            print(f"Input {i + 1}: {input_tensor.name}")
-            print(f"  Shape: {shape_list}")
-
-            # For sequence inputs (3D)
-            if len(shape) == 3:
-                seq_length = shape[1]
-                feature_count = shape[2]
-                print(f"  Sequence Length: {seq_length}")
-                print(f"  Feature Count: {feature_count}")
-
-        return model
-    except Exception as e:
-        print(f"Error loading model: {str(e)}")
-        import traceback
-        traceback.print_exc()
-        return None
-
-
-def load_feature_config(config_path):
-    """Load and analyze feature engineering configuration"""
-    print(f"\n===== LOADING FEATURE CONFIGURATION: {config_path} =====")
-
-    if os.path.exists(config_path):
-        try:
-            feature_config = joblib.load(config_path)
-
-            if isinstance(feature_config, dict):
-                if 'sequence_length' in feature_config:
-                    print(f"Sequence Length: {feature_config['sequence_length']}")
-                if 'preprocessing_params' in feature_config:
-                    params = feature_config['preprocessing_params']
-                    if 'sequential_features' in params:
-                        seq_features = params['sequential_features']
-                        print(f"Sequential Features ({len(seq_features)}): {seq_features}")
-                    if 'static_features' in params:
-                        static_features = params['static_features']
-                        print(f"Static Features ({len(static_features)}): {static_features}")
-            else:
-                print(f"Feature config type: {type(feature_config)}")
-                if hasattr(feature_config, 'sequence_length'):
-                    print(f"Sequence Length: {feature_config.sequence_length}")
-
-            return feature_config
-        except Exception as e:
-            print(f"Error loading feature configuration: {str(e)}")
-            import traceback
-            traceback.print_exc()
-    else:
-        print(f"Feature config not found at {config_path}")
-
-    return None
-
-
-def get_race_data(comp_id, db_name):
-    """Get race data for a specific race"""
-    print(f"\n===== FETCHING RACE DATA: comp={comp_id} =====")
-
-    # Initialize the race fetcher
-    config = AppConfig()
-    db_path = config.get_sqlite_dbpath(db_name)
-    race_fetcher = RaceFetcher(db_name=db_name, verbose=True)
-
-    # Fetch the race
-    race_data = race_fetcher.get_race_by_comp(comp_id)
-
-    if race_data is None:
-        print(f"Race {comp_id} not found in database")
-        return None
-
-    # Convert participants to DataFrame
-    participants = race_data.get('participants', [])
-    if isinstance(participants, str):
-        try:
-            participants = pd.read_json(participants)
-        except:
-            print("Error parsing participants JSON")
-            participants = []
-
-    if len(participants) == 0:
-        print("No participants found for this race")
-        return None
-
-    # Create DataFrame
-    df = pd.DataFrame(participants)
-
-    # Add race information to DataFrame
-    for field in ['typec', 'dist', 'natpis', 'meteo', 'temperature', 'jour',
-                  'forceVent', 'directionVent', 'corde']:
-        if field in race_data and race_data[field] is not None:
-            df[field] = race_data[field]
-
-    # Add comp to DataFrame
-    df['comp'] = comp_id
-
-    print(f"Loaded race data with {len(df)} participants")
-    print(f"Columns: {df.columns.tolist()}")
-
-    return df
-
-
-def prepare_lstm_sequence_data(race_df, orchestrator, sequence_length=5):
-    """Reproduce how LSTM sequence data is prepared during prediction"""
-    print(f"\n===== PREPARING LSTM SEQUENCE DATA =====")
-
-    # This replicates the logic in prepare_lstm_sequence_features but focuses on
-    # how it would be used during prediction
-
-    # First, apply embeddings to get enriched features
-    try:
-        embedded_df = orchestrator.apply_embeddings(
-            race_df,
-            clean_after_embedding=True,
-            keep_identifiers=True,
-            lstm_mode=True  # This ensures idche and jour are preserved
-        )
-
-        print(f"Embedded data shape: {embedded_df.shape}")
-        print(f"Embedded columns: {embedded_df.columns.tolist()}")
-
-        # Now try to fetch historical sequences
-        X_seq, X_static, y, horse_ids, race_dates = orchestrator.prepare_lstm_sequence_features(
-            embedded_df,
-            sequence_length=sequence_length
-        )
-
-        print(f"Generated sequences with shape: {X_seq.shape}")
-        print(f"Generated static features with shape: {X_static.shape}")
-        print(f"Retrieved data for {len(horse_ids)} horses")
-
-        # Check if we have sequences for all horses
-        if len(horse_ids) < len(race_df):
-            print(f"WARNING: Only generated sequences for {len(horse_ids)}/{len(race_df)} horses")
-            print(f"Missing horses: {set(race_df['idche'].unique()) - set(horse_ids)}")
-
-        return X_seq, X_static, horse_ids
-
-    except Exception as e:
-        print(f"Error preparing LSTM sequence data: {str(e)}")
-        import traceback
-        traceback.print_exc()
-        return None, None, None
-
-
-def fetch_horse_sequences_debug(race_df, db_path, sequence_length=5):
-    """Debug version of fetch_horse_sequences to diagnose sequence issues"""
-    print(f"\n===== FETCHING HISTORICAL HORSE SEQUENCES =====")
-
-    # Get all horse IDs from the race
-    horse_ids = []
-    if 'idche' in race_df.columns:
-        # Filter out missing or invalid IDs
-        horse_ids = [int(h) for h in race_df['idche'] if pd.notna(h)]
-
-    if not horse_ids:
-        print("No valid horse IDs found in race data")
-        return None, None, None
-
-    print(f"Found {len(horse_ids)} horses to fetch sequences for")
-
-    # Connect to the database
-    try:
-        conn = sqlite3.connect(db_path)
-        conn.row_factory = sqlite3.Row  # This enables column access by name
-        cursor = conn.cursor()
-
-        # Define example sequential and static features
-        # These should match what was used in training
-        sequential_features = [
-            'final_position', 'cotedirect', 'dist',
-            # Include embeddings if available
-            'horse_emb_0', 'horse_emb_1', 'horse_emb_2',
-            'jockey_emb_0', 'jockey_emb_1', 'jockey_emb_2',
-        ]
-
-        static_features = [
-            'age', 'temperature', 'natpis', 'typec', 'meteo', 'corde',
-            'couple_emb_0', 'couple_emb_1', 'couple_emb_2',
-        ]
-
-        # Prepare containers for sequences
-        all_sequences = []
-        all_static_features = []
-        all_horse_ids = []
-
-        # For each horse, retrieve its historical races
-        for horse_id in horse_ids:
-            print(f"Processing historical data for horse {horse_id}")
-
-            # Fetch historical races for this horse
-            query = """
-            SELECT hr.* 
-            FROM historical_races hr
-            WHERE hr.participants LIKE ?
-            ORDER BY hr.jour DESC
-            LIMIT 20
-            """
-
-            # Execute query
-            cursor.execute(query, (f'%"idche": {horse_id}%',))
-            horse_races = cursor.fetchall()
-
-            if not horse_races:
-                print(f"No historical races found for horse {horse_id}")
-                continue
-
-            print(f"Found {len(horse_races)} historical races for horse {horse_id}")
-
-            # Show examples of what we found
-            if len(horse_races) > 0:
-                sample_race = horse_races[0]
-                print(f"Sample race: {sample_race['comp']} on {sample_race['jour']}")
-
-                # Print the participants structure
-                try:
-                    participants_sample = json.loads(sample_race['participants'])
-                    horse_entry = next((p for p in participants_sample if int(p.get('idche', 0)) == horse_id), None)
-                    if horse_entry:
-                        print(f"Found horse in participants with keys: {horse_entry.keys()}")
-                        # List a few important keys
-                        for key in ['musiqueche', 'victoirescheval', 'placescheval']:
-                            if key in horse_entry:
-                                print(f"  {key}: {horse_entry[key]}")
-                except Exception as e:
-                    print(f"Error parsing participants: {str(e)}")
-
-        conn.close()
-
-        # If we couldn't generate sequences, show what else we could do
-        if not all_sequences:
-            print("\n===== FALLBACK OPTIONS =====")
-            print("Since we couldn't retrieve proper historical sequences, we have these options:")
-            print("1. Only use the RF model for predictions")
-            print("2. Create synthetic sequences (less accurate)")
-            print("3. Use a hybrid approach that weights RF more heavily when sequences are unavailable")
-
-        return all_sequences, all_static_features, all_horse_ids
-
-    except Exception as e:
-        print(f"Error in fetch_horse_sequences_debug: {str(e)}")
-        import traceback
-        traceback.print_exc()
-        return None, None, None
-
-
-def test_prediction_with_model(model, X_seq, X_static):
-    """Test model prediction with sequence and static data"""
-    print(f"\n===== TESTING MODEL PREDICTION =====")
-
-    if X_seq is None or X_static is None:
-        print("Cannot test prediction: Missing input data")
-        return
-
-    try:
-        # Check that shapes match model expectations
-        expected_seq_shape = model.inputs[0].shape.as_list()
-        expected_static_shape = model.inputs[1].shape.as_list()
-
-        print(f"Model expects sequence shape: {expected_seq_shape}")
-        print(f"Actual sequence data shape: {X_seq.shape}")
-
-        print(f"Model expects static shape: {expected_static_shape}")
-        print(f"Actual static data shape: {X_static.shape}")
-
-        # Check if reshape is needed
-        seq_needs_reshape = (len(X_seq.shape) != len(expected_seq_shape) or
-                             X_seq.shape[1:] != tuple(d for d in expected_seq_shape[1:] if d is not None))
-
-        static_needs_reshape = (len(X_static.shape) != len(expected_static_shape) or
-                                X_static.shape[1:] != tuple(d for d in expected_static_shape[1:] if d is not None))
-
-        if seq_needs_reshape:
-            print(f"WARNING: Sequence data needs reshaping to match model expectations")
-            # Try to reshape if possible (this is just for testing)
-            if len(X_seq.shape) == 2 and len(expected_seq_shape) == 3:
-                # If we have (batch, features) but need (batch, seq_len, features)
-                # Assuming features can be reshaped into seq_len * new_features
-                batch_size = X_seq.shape[0]
-                if expected_seq_shape[1] is not None:
-                    seq_len = expected_seq_shape[1]
-                    # Calculate new feature dim to maintain the same total elements
-                    total_elements = X_seq.shape[1]
-                    if total_elements % seq_len == 0:
-                        new_feat_dim = total_elements // seq_len
-                        X_seq = X_seq.reshape(batch_size, seq_len, new_feat_dim)
-                        print(f"Reshaped sequence data to: {X_seq.shape}")
-
-        if static_needs_reshape:
-            print(f"WARNING: Static data needs reshaping to match model expectations")
-            # Could implement similar reshaping logic for static data if needed
-
-        # Make prediction
-        prediction = model.predict([X_seq, X_static], verbose=0)
-
-        print(f"Prediction successful with shape: {prediction.shape}")
-        print(f"Prediction values: {prediction.flatten()}")
-
-    except Exception as e:
-        print(f"Error testing prediction: {str(e)}")
-        import traceback
-        traceback.print_exc()
-
-
-
-
-
-if __name__ == "__main__":
-    # Initialize the configuration
-    config = AppConfig()
-    db_path = config.get_sqlite_dbpath(DB_NAME)
-
-    # Initialize orchestrator
-    orchestrator = FeatureEmbeddingOrchestrator(
-        sqlite_path=db_path,
-        verbose=True
-    )
-
-    # Load and analyze the model
-    model = analyze_model(MODEL_PATH)
-
-    # Load feature configuration
-    feature_config = load_feature_config(FEATURE_CONFIG_PATH)
-
-    # Update orchestrator with feature config if available
-    if feature_config and isinstance(feature_config, dict):
-        if 'preprocessing_params' in feature_config:
-            orchestrator.preprocessing_params.update(feature_config['preprocessing_params'])
-        if 'sequence_length' in feature_config:
-            orchestrator.sequence_length = feature_config['sequence_length']
-
-    # Get race data for specific race
-    race_df = get_race_data(COMP_ID, DB_NAME)
-
-    if race_df is not None:
-        # Try preparing LSTM sequence data
-        if model is not None:
-            sequence_length = 5  # From model summary
-
-            # Prepare sequences
-            X_seq, X_static, horse_ids = prepare_lstm_sequence_data(
-                race_df,
-                orchestrator,
-                sequence_length
-            )
-
-            # Debug direct sequence fetching
-            fetch_horse_sequences_debug(race_df, db_path, sequence_length)
-
-            # Test prediction with model if we have sequences
-            if X_seq is not None and X_static is not None:
-                test_prediction_with_model(model, X_seq, X_static)
-
Index: test.py
===================================================================
diff --git a/test.py b/test.py
deleted file mode 100644
--- a/test.py	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
+++ /dev/null	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
@@ -1,4 +0,0 @@
-import torch
-print(f"PyTorch version: {torch.__version__}")
-print(f"MPS available: {torch.backends.mps.is_available()}")
-print(f"MPS built: {torch.backends.mps.is_built()}")
\ No newline at end of file
Index: bot.py
===================================================================
diff --git a/bot.py b/bot.py
deleted file mode 100644
--- a/bot.py	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
+++ /dev/null	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
@@ -1,166 +0,0 @@
-from pathlib import Path
-from datetime import datetime
-import time
-from typing import List, Dict, Optional
-
-# Import your existing modules
-from core.orchestrators.prediction_orchestrator import PredictionOrchestrator
-from utils.TelegramNotifier import TelegramNotifier
-from utils.env_setup import AppConfig
-#from core.database import Database
-
-
-class PredictionBot:
-    """Simplified bot for IDE usage - no command line needed."""
-
-    def __init__(self):
-        """Initialize with hardcoded values for simplicity."""
-        # CONFIGURATION - Change these values as needed
-        self.MODEL_PATH = "models/2years/hybrid/2years_full_v20250409"  # Your model path
-        self.CONFIG_PATH = "config.yaml"
-
-        # Load configuration
-        self.config = setup_environment(self.CONFIG_PATH)
-        self.db = Database()
-
-        # Initialize prediction orchestrator
-        print(f"Loading model from: {self.MODEL_PATH}")
-        self.orchestrator = PredictionOrchestrator(
-            model_path=self.MODEL_PATH,
-            db_name=self.config.get('active_db'),
-            verbose=True
-        )
-
-        # Initialize telegram
-        self.telegram = TelegramNotifier(
-            self.config['telegram']['bot_token'],
-            self.config['telegram']['chat_id']
-        )
-        self.telegram.callback_handler = self.predict_race
-
-    def predict_race(self, comp_id: int) -> None:
-        """Generate and send prediction for a race."""
-        print(f"\n{'=' * 50}")
-        print(f"Predicting race {comp_id}")
-        print(f"{'=' * 50}")
-
-        # Get race details
-        with self.db.get_connection() as conn:
-            cursor = conn.execute('''
-                SELECT hippodrome, heure, prixnom, quinte, jour
-                FROM daily_races
-                WHERE comp = ?
-            ''', (comp_id,))
-            race_data = cursor.fetchone()
-
-        if not race_data:
-            self.telegram.send_message(f"❌ Race {comp_id} not found")
-            return
-
-        hippo, heure, prixnom, is_quinte, jour = race_data
-
-        # Run prediction
-        result = self.orchestrator.predict_race(comp_id)
-
-        if result['status'] == 'success':
-            # Build message
-            predictions = result['predictions']
-
-            lines = [
-                f"{'🌟' if is_quinte else '🏇'} <b>{hippo} - {heure}</b>",
-                f"📍 {prixnom} ({jour})",
-                "",
-                "<b>Arrivée prédite:</b>"
-            ]
-
-            # Top 5 horses
-            for i, horse in enumerate(predictions[:5], 1):
-                lines.append(f"{i}. {horse['numero']} - {horse['cheval']}")
-
-            # Full arrival string
-            if result['metadata'].get('predicted_arriv'):
-                lines.extend(["", f"📋 {result['metadata']['predicted_arriv']}"])
-
-            self.telegram.send_message("\n".join(lines))
-            print("✅ Prediction sent to Telegram")
-        else:
-            self.telegram.send_message(f"❌ Error: {result.get('error', 'Unknown')}")
-            print(f"❌ Prediction failed: {result.get('error')}")
-
-    def send_today_races(self, date: str = None) -> None:
-        """Fetch today's races and send list to Telegram."""
-        if not date:
-            date = datetime.now().strftime("%Y-%m-%d")
-
-        print(f"\nFetching races for {date}...")
-
-        # Fetch from API and store
-        fetch_result = self.orchestrator.race_fetcher.fetch_and_store_daily_races(date)
-
-        if fetch_result['status'] == 'error':
-            print(f"Error fetching races: {fetch_result['error']}")
-            return
-
-        print(f"Fetched {fetch_result['successful']} races")
-
-        # Get races from DB for display
-        with self.db.get_connection() as conn:
-            cursor = conn.execute('''
-                SELECT comp, hippodrome, reun, prix, heure, prixnom, quinte
-                FROM daily_races
-                WHERE jour = ?
-                ORDER BY heure
-            ''', (date,))
-
-            races = []
-            for row in cursor.fetchall():
-                races.append({
-                    'numcourse': {
-                        'comp': row[0],
-                        'hippo': row[1],
-                        'reun': row[2],
-                        'prix': row[3],
-                        'heure': row[4],
-                        'prixnom': row[5],
-                        'quinte': row[6]
-                    }
-                })
-
-        if races:
-            print(f"Sending {len(races)} races to Telegram...")
-            self.telegram.send_daily_races(races)
-        else:
-            print("No races to send")
-
-    def run_bot(self):
-        """Start the bot and keep it running."""
-        # Send today's races
-        self.send_today_races()
-
-        # Start polling
-        print("\n🤖 Bot is running! Click on races in Telegram to get predictions.")
-        print("Press Ctrl+C to stop\n")
-
-        self.telegram.start_polling()
-
-        # Keep running
-        while True:
-            time.sleep(1)
-
-
-# Direct usage - no command line needed
-if __name__ == "__main__":
-    # Create bot instance
-    bot = PredictionBot()
-
-    # Option 1: Run full bot (sends races and waits for clicks)
-    bot.run_bot()
-
-    # Option 2: Just send today's races (uncomment to use)
-    # bot.send_today_races()
-
-    # Option 3: Predict a specific race (uncomment to use)
-    # bot.predict_race(12345)  # Replace with actual comp_id
-
-    # Option 4: Send races for specific date (uncomment to use)
-    # bot.send_today_races("2025-01-15")
\ No newline at end of file
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"43ec0894-de26-497b-a8fc-a968059a9170\" name=\"Changes\" comment=\"Well... Final Version!!\">\n      <change afterPath=\"$PROJECT_DIR$/cache/historical_data/historical_data.parquet\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/UI/UIApp.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/UI/UIApp.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/UI/UIhelper.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/UI/UIhelper.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/config.yaml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/config.yaml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/core/calculators/static_feature_calculator.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/core/calculators/static_feature_calculator.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/core/orchestrators/embedding_feature.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/core/orchestrators/embedding_feature.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/model_training/features/couple_embedding.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/model_training/features/couple_embedding.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/model_training/historical/train_race_model.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/model_training/historical/train_race_model.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/model_training/regressions/regression_enhancement.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/model_training/regressions/regression_enhancement.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/race_prediction/daily_predictor.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/race_prediction/daily_predictor.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/race_prediction/race_predict.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/race_prediction/race_predict.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/test.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/test.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utils/ai_advisor.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utils/ai_advisor.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/utils/cache_manager.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/utils/cache_manager.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n    <option name=\"UPDATE_TYPE\" value=\"REBASE\" />\n  </component>\n  <component name=\"GitHubPullRequestSearchHistory\">{\n  &quot;lastFilter&quot;: {\n    &quot;state&quot;: &quot;OPEN&quot;,\n    &quot;assignee&quot;: &quot;Mattg0&quot;\n  }\n}</component>\n  <component name=\"GithubPullRequestsUISettings\">{\n  &quot;selectedUrlAndAccountId&quot;: {\n    &quot;url&quot;: &quot;https://github.com/Mattg0/HorseAI.git&quot;,\n    &quot;accountId&quot;: &quot;aee67ed6-2c23-4be9-a632-2459e76288ac&quot;\n  }\n}</component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 4\n}</component>\n  <component name=\"ProjectId\" id=\"2tOCkYF0cZhZtRPomssp0yLhNGU\" />\n  <component name=\"ProjectLevelVcsManager\" settingsEditedManually=\"true\" />\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\"><![CDATA[{\n  \"keyToString\": {\n    \"Python.UIApp.executor\": \"Run\",\n    \"Python.api_daily_sync.executor\": \"Run\",\n    \"Python.blend_testing.executor\": \"Run\",\n    \"Python.comprehensive_training.executor\": \"Run\",\n    \"Python.daily_predictor.executor\": \"Run\",\n    \"Python.debug_json_pipeline.executor\": \"Run\",\n    \"Python.embedding_feature.executor\": \"Run\",\n    \"Python.env_setup.executor\": \"Run\",\n    \"Python.envdebug.executor\": \"Run\",\n    \"Python.horse_embedding.executor\": \"Run\",\n    \"Python.musique_calculation.executor\": \"Debug\",\n    \"Python.mysql_connector.executor\": \"Run\",\n    \"Python.mysql_sqlite_sync.executor\": \"Run\",\n    \"Python.mysql_to_sqlite.executor\": \"Run\",\n    \"Python.predict_daily_races.executor\": \"Run\",\n    \"Python.predict_evaluator.executor\": \"Run\",\n    \"Python.predict_orchestrator_cli.executor\": \"Run\",\n    \"Python.prediction_orchestrator.executor\": \"Run\",\n    \"Python.race_predict.executor\": \"Run\",\n    \"Python.regression_enhancement.executor\": \"Run\",\n    \"Python.streamlit.executor\": \"Run\",\n    \"Python.tabnet_model.executor\": \"Run\",\n    \"Python.test.executor\": \"Debug\",\n    \"Python.three_model_race_predict.executor\": \"Run\",\n    \"Python.train_model.executor\": \"Debug\",\n    \"Python.train_race_model.executor\": \"Run\",\n    \"Python.train_tabnet.executor\": \"Run\",\n    \"RunOnceActivity.ShowReadmeOnStart\": \"true\",\n    \"RunOnceActivity.git.unshallow\": \"true\",\n    \"git-widget-placeholder\": \"TabnetV1\"\n  }\n}]]></component>\n  <component name=\"RecentsManager\">\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/core/connectors\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.regression_enhancement\">\n    <configuration name=\"comprehensive_training\" type=\"PythonConfigurationType\" factoryName=\"Python\" nameIsGenerated=\"true\">\n      <module name=\"HorseAIv2\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/model_training/comprehensive_training.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"daily_predictor\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"HorseAIv2\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/race_prediction/daily_predictor.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"predict_daily_races\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"HorseAIv2\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/race_prediction\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/race_prediction/predict_daily_races.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"race_predict\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"HorseAIv2\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/race_prediction/race_predict.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"regression_enhancement\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"HorseAIv2\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/model_training/regressions/regression_enhancement.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"train_tabnet\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"HorseAIv2\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/model_training/tabnet/train_tabnet.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <list>\n      <item itemvalue=\"Python.comprehensive_training\" />\n      <item itemvalue=\"Python.regression_enhancement\" />\n      <item itemvalue=\"Python.race_predict\" />\n      <item itemvalue=\"Python.train_tabnet\" />\n      <item itemvalue=\"Python.daily_predictor\" />\n      <item itemvalue=\"Python.predict_daily_races\" />\n    </list>\n    <recent_temporary>\n      <list>\n        <item itemvalue=\"Python.regression_enhancement\" />\n        <item itemvalue=\"Python.race_predict\" />\n        <item itemvalue=\"Python.daily_predictor\" />\n        <item itemvalue=\"Python.train_tabnet\" />\n        <item itemvalue=\"Python.predict_daily_races\" />\n      </list>\n    </recent_temporary>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-python-sdk-4f4e415b4190-aa17d162503b-com.jetbrains.pycharm.community.sharedIndexes.bundled-PC-243.26053.29\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"43ec0894-de26-497b-a8fc-a968059a9170\" name=\"Changes\" comment=\"\" />\n      <created>1740213877566</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1740213877566</updated>\n    </task>\n    <task id=\"LOCAL-00001\" summary=\"Project Initialisiation\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1740556622361</created>\n      <option name=\"number\" value=\"00001\" />\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1740556622361</updated>\n    </task>\n    <task id=\"LOCAL-00002\" summary=\"Working MySQL connector!\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1740584410696</created>\n      <option name=\"number\" value=\"00002\" />\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1740584410696</updated>\n    </task>\n    <task id=\"LOCAL-00003\" summary=\"modular mysql&lt;-&gt;sqlite sync\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1740650477583</created>\n      <option name=\"number\" value=\"00003\" />\n      <option name=\"presentableId\" value=\"LOCAL-00003\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1740650477583</updated>\n    </task>\n    <task id=\"LOCAL-00004\" summary=\"adding embeddings\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1740659886795</created>\n      <option name=\"number\" value=\"00004\" />\n      <option name=\"presentableId\" value=\"LOCAL-00004\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1740659886795</updated>\n    </task>\n    <task id=\"LOCAL-00005\" summary=\"adding cache manager\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1740693327554</created>\n      <option name=\"number\" value=\"00005\" />\n      <option name=\"presentableId\" value=\"LOCAL-00005\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1740693327554</updated>\n    </task>\n    <task id=\"LOCAL-00006\" summary=\"updating embedding feature with config approach\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1740755058414</created>\n      <option name=\"number\" value=\"00006\" />\n      <option name=\"presentableId\" value=\"LOCAL-00006\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1740755058414</updated>\n    </task>\n    <task id=\"LOCAL-00007\" summary=\"updating embedding feature with config approach\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1740920224165</created>\n      <option name=\"number\" value=\"00007\" />\n      <option name=\"presentableId\" value=\"LOCAL-00007\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1740920224165</updated>\n    </task>\n    <task id=\"LOCAL-00008\" summary=\"updating embedding feature with config approach\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741207626289</created>\n      <option name=\"number\" value=\"00008\" />\n      <option name=\"presentableId\" value=\"LOCAL-00008\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741207626289</updated>\n    </task>\n    <task id=\"LOCAL-00009\" summary=\"refactored_horse_embedding\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741207970875</created>\n      <option name=\"number\" value=\"00009\" />\n      <option name=\"presentableId\" value=\"LOCAL-00009\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741207970875</updated>\n    </task>\n    <task id=\"LOCAL-00010\" summary=\"refactored_couple_embedding\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1741208877518</created>\n      <option name=\"number\" value=\"00010\" />\n      <option name=\"presentableId\" value=\"LOCAL-00010\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1741208877518</updated>\n    </task>\n    <task id=\"LOCAL-00011\" summary=\"refactored_cache_manager\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1742135265333</created>\n      <option name=\"number\" value=\"00011\" />\n      <option name=\"presentableId\" value=\"LOCAL-00011\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1742135265333</updated>\n    </task>\n    <task id=\"LOCAL-00012\" summary=\"fixed cache_manager &amp; orchestrator\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1742200198713</created>\n      <option name=\"number\" value=\"00012\" />\n      <option name=\"presentableId\" value=\"LOCAL-00012\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1742200198713</updated>\n    </task>\n    <task id=\"LOCAL-00013\" summary=\"fixing feature storing and loading with testing\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1742201779545</created>\n      <option name=\"number\" value=\"00013\" />\n      <option name=\"presentableId\" value=\"LOCAL-00013\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1742201779545</updated>\n    </task>\n    <task id=\"LOCAL-00014\" summary=\"fixed feature embedding\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1742226900595</created>\n      <option name=\"number\" value=\"00014\" />\n      <option name=\"presentableId\" value=\"LOCAL-00014\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1742226900595</updated>\n    </task>\n    <task id=\"LOCAL-00015\" summary=\"fixed feature embedding\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1742541186315</created>\n      <option name=\"number\" value=\"00015\" />\n      <option name=\"presentableId\" value=\"LOCAL-00015\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1742541186315</updated>\n    </task>\n    <task id=\"LOCAL-00016\" summary=\"fixed feature embedding\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1742549204949</created>\n      <option name=\"number\" value=\"00016\" />\n      <option name=\"presentableId\" value=\"LOCAL-00016\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1742549204949</updated>\n    </task>\n    <task id=\"LOCAL-00017\" summary=\"fixed feature embedding\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1742825115896</created>\n      <option name=\"number\" value=\"00017\" />\n      <option name=\"presentableId\" value=\"LOCAL-00017\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1742825115896</updated>\n    </task>\n    <task id=\"LOCAL-00018\" summary=\"adding daily races sync\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1742903024757</created>\n      <option name=\"number\" value=\"00018\" />\n      <option name=\"presentableId\" value=\"LOCAL-00018\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1742903024757</updated>\n    </task>\n    <task id=\"LOCAL-00019\" summary=\"adding daily races sync\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743020439512</created>\n      <option name=\"number\" value=\"00019\" />\n      <option name=\"presentableId\" value=\"LOCAL-00019\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743020439512</updated>\n    </task>\n    <task id=\"LOCAL-00020\" summary=\"adding daily races sync\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1743421163636</created>\n      <option name=\"number\" value=\"00020\" />\n      <option name=\"presentableId\" value=\"LOCAL-00020\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1743421163636</updated>\n    </task>\n    <task id=\"LOCAL-00021\" summary=\"ModelManager\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1744094884798</created>\n      <option name=\"number\" value=\"00021\" />\n      <option name=\"presentableId\" value=\"LOCAL-00021\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1744094884798</updated>\n    </task>\n    <task id=\"LOCAL-00022\" summary=\"ModelManager\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1744176790455</created>\n      <option name=\"number\" value=\"00022\" />\n      <option name=\"presentableId\" value=\"LOCAL-00022\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1744176790455</updated>\n    </task>\n    <task id=\"LOCAL-00023\" summary=\"Final Version!!\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1744279324131</created>\n      <option name=\"number\" value=\"00023\" />\n      <option name=\"presentableId\" value=\"LOCAL-00023\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1744279324131</updated>\n    </task>\n    <task id=\"LOCAL-00024\" summary=\"Well... Final Version!!\">\n      <option name=\"closed\" value=\"true\" />\n      <created>1744702346043</created>\n      <option name=\"number\" value=\"00024\" />\n      <option name=\"presentableId\" value=\"LOCAL-00024\" />\n      <option name=\"project\" value=\"LOCAL\" />\n      <updated>1744702346043</updated>\n    </task>\n    <option name=\"localTasksCounter\" value=\"25\" />\n    <servers />\n  </component>\n  <component name=\"VcsManagerConfiguration\">\n    <MESSAGE value=\"Project Initialisiation\" />\n    <MESSAGE value=\"Working MySQL connector!\" />\n    <MESSAGE value=\"modular mysql&lt;-&gt;sqlite sync\" />\n    <MESSAGE value=\"adding embeddings\" />\n    <MESSAGE value=\"adding cache manager\" />\n    <MESSAGE value=\"updating embedding feature with config approach\" />\n    <MESSAGE value=\"refactored_horse_embedding\" />\n    <MESSAGE value=\"refactored_couple_embedding\" />\n    <MESSAGE value=\"refactored_cache_manager\" />\n    <MESSAGE value=\"fixed cache_manager &amp; orchestrator\" />\n    <MESSAGE value=\"fixing feature storing and loading with testing\" />\n    <MESSAGE value=\"fixed feature embedding\" />\n    <MESSAGE value=\"adding daily races sync\" />\n    <MESSAGE value=\"ModelManager\" />\n    <MESSAGE value=\"Final Version!!\" />\n    <MESSAGE value=\"Well... Final Version!!\" />\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"Well... Final Version!!\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/calculators/static_feature_calculator.py</url>\n          <line>171</line>\n          <option name=\"timeStamp\" value=\"30\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/transformers/historical_race_transformer.py</url>\n          <line>84</line>\n          <option name=\"timeStamp\" value=\"55\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/race_prediction/predict_daily_races.py</url>\n          <line>125</line>\n          <option name=\"timeStamp\" value=\"98\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/calculators/static_feature_calculator.py</url>\n          <line>93</line>\n          <option name=\"timeStamp\" value=\"139\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/calculators/static_feature_calculator.py</url>\n          <line>157</line>\n          <option name=\"timeStamp\" value=\"140\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/race_prediction/predict_daily_races.py</url>\n          <line>54</line>\n          <option name=\"timeStamp\" value=\"166\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/model_training/regressions/error_correction.py</url>\n          <line>79</line>\n          <option name=\"timeStamp\" value=\"234\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>816</line>\n          <option name=\"timeStamp\" value=\"336\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>657</line>\n          <option name=\"timeStamp\" value=\"338\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>659</line>\n          <option name=\"timeStamp\" value=\"339\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>682</line>\n          <option name=\"timeStamp\" value=\"340\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>681</line>\n          <option name=\"timeStamp\" value=\"341\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>747</line>\n          <option name=\"timeStamp\" value=\"342\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>684</line>\n          <option name=\"timeStamp\" value=\"343\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>688</line>\n          <option name=\"timeStamp\" value=\"344\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>691</line>\n          <option name=\"timeStamp\" value=\"345\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>694</line>\n          <option name=\"timeStamp\" value=\"346\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>740</line>\n          <option name=\"timeStamp\" value=\"347\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>735</line>\n          <option name=\"timeStamp\" value=\"349\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>731</line>\n          <option name=\"timeStamp\" value=\"350\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>727</line>\n          <option name=\"timeStamp\" value=\"351\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>719</line>\n          <option name=\"timeStamp\" value=\"353\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>712</line>\n          <option name=\"timeStamp\" value=\"354\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>715</line>\n          <option name=\"timeStamp\" value=\"355\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>716</line>\n          <option name=\"timeStamp\" value=\"356\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>705</line>\n          <option name=\"timeStamp\" value=\"357\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/connectors/api_daily_sync.py</url>\n          <line>719</line>\n          <option name=\"timeStamp\" value=\"359\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/connectors/api_daily_sync.py</url>\n          <line>722</line>\n          <option name=\"timeStamp\" value=\"360\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/connectors/api_daily_sync.py</url>\n          <line>720</line>\n          <option name=\"timeStamp\" value=\"361\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>\n          <line>107</line>\n          <option name=\"timeStamp\" value=\"362\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/race_prediction/daily_predictor.py</url>\n          <option name=\"timeStamp\" value=\"364\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/model_training/regressions/regression_enhancement.py</url>\n          <line>120</line>\n          <option name=\"timeStamp\" value=\"377\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/utils/ai_advisor.py</url>\n          <line>749</line>\n          <option name=\"timeStamp\" value=\"404\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n    <watches-manager>\n      <configuration name=\"PythonConfigurationType\">\n        <watch expression=\"race_type['course_info']\" language=\"Python\" />\n        <watch expression=\"musique_stats.race_types.__len__()\" />\n        <watch expression=\"musique_stats.__len__()\" />\n        <watch expression=\"result_df['error']\" />\n        <watch expression=\"result_df['error']\" />\n      </configuration>\n    </watches-manager>\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
+++ b/.idea/workspace.xml	(date 1759478048646)
@@ -5,22 +5,14 @@
   </component>
   <component name="ChangeListManager">
     <list default="true" id="43ec0894-de26-497b-a8fc-a968059a9170" name="Changes" comment="Well... Final Version!!">
-      <change afterPath="$PROJECT_DIR$/cache/historical_data/historical_data.parquet" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/UI/UIApp.py" beforeDir="false" afterPath="$PROJECT_DIR$/UI/UIApp.py" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/UI/UIhelper.py" beforeDir="false" afterPath="$PROJECT_DIR$/UI/UIhelper.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/bot.py" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/cache/historical_data/historical_data.parquet" beforeDir="false" />
       <change beforePath="$PROJECT_DIR$/config.yaml" beforeDir="false" afterPath="$PROJECT_DIR$/config.yaml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/core/calculators/static_feature_calculator.py" beforeDir="false" afterPath="$PROJECT_DIR$/core/calculators/static_feature_calculator.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/core/orchestrators/embedding_feature.py" beforeDir="false" afterPath="$PROJECT_DIR$/core/orchestrators/embedding_feature.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py" beforeDir="false" afterPath="$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/model_training/features/couple_embedding.py" beforeDir="false" afterPath="$PROJECT_DIR$/model_training/features/couple_embedding.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/model_training/historical/train_race_model.py" beforeDir="false" afterPath="$PROJECT_DIR$/model_training/historical/train_race_model.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/model_training/regressions/regression_enhancement.py" beforeDir="false" afterPath="$PROJECT_DIR$/model_training/regressions/regression_enhancement.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/race_prediction/daily_predictor.py" beforeDir="false" afterPath="$PROJECT_DIR$/race_prediction/daily_predictor.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/race_prediction/race_predict.py" beforeDir="false" afterPath="$PROJECT_DIR$/race_prediction/race_predict.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/test.py" beforeDir="false" afterPath="$PROJECT_DIR$/test.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/utils/ai_advisor.py" beforeDir="false" afterPath="$PROJECT_DIR$/utils/ai_advisor.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/utils/cache_manager.py" beforeDir="false" afterPath="$PROJECT_DIR$/utils/cache_manager.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/lstmdebug.py" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/test.py" beforeDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -95,7 +87,7 @@
     "Python.train_tabnet.executor": "Run",
     "RunOnceActivity.ShowReadmeOnStart": "true",
     "RunOnceActivity.git.unshallow": "true",
-    "git-widget-placeholder": "TabnetV1"
+    "git-widget-placeholder": "main"
   }
 }]]></component>
   <component name="RecentsManager">
@@ -487,30 +479,10 @@
   <component name="XDebuggerManager">
     <breakpoint-manager>
       <breakpoints>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/core/calculators/static_feature_calculator.py</url>
-          <line>171</line>
-          <option name="timeStamp" value="30" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/core/transformers/historical_race_transformer.py</url>
-          <line>84</line>
-          <option name="timeStamp" value="55" />
-        </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/race_prediction/predict_daily_races.py</url>
           <line>125</line>
           <option name="timeStamp" value="98" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/core/calculators/static_feature_calculator.py</url>
-          <line>93</line>
-          <option name="timeStamp" value="139" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/core/calculators/static_feature_calculator.py</url>
-          <line>157</line>
-          <option name="timeStamp" value="140" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/race_prediction/predict_daily_races.py</url>
@@ -616,21 +588,6 @@
           <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>
           <line>705</line>
           <option name="timeStamp" value="357" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/core/connectors/api_daily_sync.py</url>
-          <line>719</line>
-          <option name="timeStamp" value="359" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/core/connectors/api_daily_sync.py</url>
-          <line>722</line>
-          <option name="timeStamp" value="360" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/core/connectors/api_daily_sync.py</url>
-          <line>720</line>
-          <option name="timeStamp" value="361" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/core/orchestrators/prediction_orchestrator.py</url>
Index: UI/UIhelper.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\nimport yaml\nimport json\nimport os\nimport re\nfrom datetime import datetime\nfrom typing import Dict, Any, Tuple, Optional, List\nimport threading\nimport queue\nimport sys\nfrom pathlib import Path\n\n# Add project root to Python path\ncurrent_dir = Path(__file__).parent  # UI directory\nproject_root = current_dir.parent    # HorseAIv2 directory\nif str(project_root) not in sys.path:\n    sys.path.insert(0, str(project_root))\n\nfrom utils.env_setup import AppConfig\nfrom model_training.historical import train_race_model\nfrom core.connectors.api_daily_sync import RaceFetcher\nfrom core.orchestrators.prediction_orchestrator import PredictionOrchestrator\nfrom utils.predict_evaluator import PredictEvaluator\nfrom model_training.regressions.regression_enhancement import IncrementalTrainingPipeline\nfrom utils.ai_advisor import BettingAdvisor\n\nclass PipelineHelper:\n    \"\"\"Helper class for config management and status calculations\"\"\"\n\n    def __init__(self, config_path: str = 'config.yaml'):\n        self.config_path = config_path\n        self._config_data = self.load_config()\n\n        # Training management\n        self.training_queue = queue.Queue()\n        self.training_thread = None\n        self.is_training = False\n\n    def load_config(self) -> Optional[Dict[str, Any]]:\n        \"\"\"Load config.yaml file\"\"\"\n        try:\n            if os.path.exists(self.config_path):\n                with open(self.config_path, 'r') as file:\n                    self._config_data = yaml.safe_load(file)\n                    return self._config_data\n            return None\n        except Exception as e:\n            raise Exception(f\"Error loading config: {str(e)}\")\n\n    def save_config(self, updated_config: Dict[str, Any]) -> bool:\n        \"\"\"Save updated config to config.yaml\"\"\"\n        try:\n            with open(self.config_path, 'w') as file:\n                yaml.dump(updated_config, file, default_flow_style=False, sort_keys=False)\n            self._config_data = updated_config\n            return True\n        except Exception as e:\n            raise Exception(f\"Error saving config: {str(e)}\")\n\n    def get_config_json(self) -> str:\n        \"\"\"Get current config as formatted JSON\"\"\"\n        if self._config_data:\n            return json.dumps(self._config_data, indent=2)\n        return \"No configuration loaded\"\n\n    def get_active_db(self) -> str:\n        \"\"\"Get active database from config\"\"\"\n        print(f\"Config data: {self._config_data}\")  # Debug line\n        if self._config_data and 'base' in self._config_data:\n            print(f\"Base section: {self._config_data['base']}\")  # Debug line\n            return self._config_data['base'].get('active_db', 'Unknown')\n        return 'Unknown'\n\n    def get_sqlite_databases(self) -> list:\n        \"\"\"Get list of SQLite databases from config\"\"\"\n        if not self._config_data or 'databases' not in self._config_data:\n            return []\n        return [db['name'] for db in self._config_data['databases'] if db.get('type') == 'sqlite']\n\n    def get_last_training_info(self) -> Tuple[str, str]:\n        \"\"\"Extract last training date and version from model names\"\"\"\n        if not self._config_data or 'models' not in self._config_data:\n            return 'Unknown', 'Unknown'\n\n        models = self._config_data['models']\n        latest_model = (models.get('latest_model'))\n\n        if latest_model:\n            # Extract date from model name like \"5years_hybrid_v20250606_182331\"\n            date_match = re.search(r'(\\d{4}-\\d{2}-\\d{2})', latest_model)\n            if date_match:\n                date_str = date_match.group(1)\n                try:\n                    training_date = datetime.strptime(date_str, '%Y-%m-%d')\n                    days_ago = (datetime.now() - training_date).days\n\n                    if days_ago == 0:\n                        last_training = \"Today\"\n                    elif days_ago == 1:\n                        last_training = \"Yesterday\"\n                    else:\n                        last_training = f\"{days_ago} days ago\"\n\n                    version = latest_model.split('_')[-2] + '_' + latest_model.split('_')[-1]\n                    return last_training, version\n                except:\n                    pass\n\n        return 'Unknown', 'Unknown'\n\n    def get_system_status(self) -> Dict[str, str]:\n        \"\"\"Get complete system status\"\"\"\n        if not self._config_data:\n            self.load_config()\n\n        last_training, model_version = self.get_last_training_info()\n\n        return {\n            'active_db': self.get_active_db(),\n            'last_training': last_training,\n            'model_version': model_version\n        }\n\n    def get_config_sections(self) -> Dict[str, Any]:\n        \"\"\"Get organized config sections for UI editing\"\"\"\n        if not self._config_data:\n            return {}\n\n        return {\n            'base': self._config_data.get('base', {}),\n            'features': self._config_data.get('features', {}),\n            'lstm': self._config_data.get('lstm', {}),\n            'dataset': self._config_data.get('dataset', {}),\n            'cache': self._config_data.get('cache', {}),\n            'databases': self._config_data.get('databases', []),\n            'blend': self._config_data.get('blend', {})\n        }\n\n    def update_config_section(self, section: str, updates: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Update a specific config section and return full config\"\"\"\n        if not self._config_data:\n            self.load_config()\n\n        config_copy = self._config_data.copy()\n\n        if section in config_copy:\n            config_copy[section].update(updates)\n        else:\n            config_copy[section] = updates\n\n        return config_copy\n\n    def execute_full_training(self, progress_callback) -> Dict[str, Any]:\n        \"\"\"Execute full model training\"\"\"\n        try:\n            # Simply call the main training function\n            train_race_model.main(progress_callback)\n\n            return {\n                \"success\": True,\n                \"message\": \"Training completed successfully\"\n            }\n\n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"message\": f\"Training failed: {str(e)}\"\n            }\n\n    def start_training_async(self) -> bool:\n        \"\"\"Start training in background thread\"\"\"\n        if self.is_training:\n            return False\n\n        self.is_training = True\n        self.training_thread = threading.Thread(\n            target=self._training_worker,\n            daemon=True\n        )\n        self.training_thread.start()\n        return True\n\n    def _training_worker(self):\n        \"\"\"Background training worker\"\"\"\n        try:\n            def progress_callback(percent, message):\n                self.training_queue.put({\n                    'type': 'progress',\n                    'percent': percent,\n                    'message': message\n                })\n\n            # Run actual training\n            train_race_model.main(progress_callback=progress_callback)\n\n            # Send completion\n            self.training_queue.put({\n                'type': 'complete',\n                'success': True,\n                'message': 'Training completed successfully'\n            })\n        except Exception as e:\n            self.training_queue.put({\n                'type': 'complete',\n                'success': False,\n                'error': str(e),\n                'message': f'Training failed: {str(e)}'\n            })\n        finally:\n            self.is_training = False\n\n    def get_training_updates(self) -> List[Dict[str, Any]]:\n        \"\"\"Get latest training updates\"\"\"\n        updates = []\n        try:\n            while True:\n                update = self.training_queue.get_nowait()\n                updates.append(update)\n        except queue.Empty:\n            pass\n        return updates\n    # Prediction operations\n    def get_daily_races(self) -> List[Dict[str, Any]]:\n        \"\"\"Get races from daily_race table for a specific date\"\"\"\n        if not self._config_data:\n          self.load_config()\n\n            # Initialize race fetcher\n        race_fetcher = RaceFetcher()\n\n            # Get races for the date\n        races = race_fetcher.get_all_daily_races()\n\n        return races\n\n    def sync_daily_races(self,date) -> List[Dict[str, Any]]:\n        race_fetcher = RaceFetcher()\n        if date is None:\n            date = datetime.today().strftime(\"%Y-%m-%d\")\n        race_fetcher.fetch_and_store_daily_races(date)\n\n    def get_races_needing_prediction(self) -> List[Dict[str, Any]]:\n        \"\"\"Get races that need predictions (don't have prediction_results)\"\"\"\n        date = datetime.today().strftime(\"%Y-%m-%d\")\n\n        races = self.get_daily_races()\n\n            # Filter races that need predictions\n        unpredicted_races = [\n            race for race in races\n            if race.get('has_predictions', 0) == 0 and race.get('has_processed_data', 0) == 1\n        ]\n\n        return unpredicted_races\n\n    def get_races_for_reprediction(self, date: str = None) -> List[Dict[str, Any]]:\n        \"\"\"Get all races with processed data (for force reprediction)\"\"\"\n        try:\n            races = self.get_daily_races()\n\n            # Filter races that have processed data (ignore prediction status)\n            reprediction_races = [\n                race for race in races\n                if race.get('has_processed_data', 0) == 1\n            ]\n\n            return reprediction_races\n\n        except Exception as e:\n            raise Exception(f\"Error getting races for reprediction: {str(e)}\")\n\n    def execute_predictions(self, races_to_predict: List[str] = None, progress_callback=None,\n                            force_reprediction: bool = False) -> Dict[str, Any]:\n        \"\"\"Execute predictions for specified races or all unpredicted races\"\"\"\n        try:\n            if progress_callback:\n                progress_callback(5, \"Initializing prediction orchestrator...\")\n\n            # Initialize prediction orchestrator\n            predictor = PredictionOrchestrator()\n            \n            # Get model information for debugging\n            model_info = predictor.get_model_info()\n            models_loaded = model_info.get('models_loaded', {})\n            \n            # Debug output showing which models are loaded\n            debug_message = f\"Models loaded: RF={models_loaded.get('rf', False)}, LSTM={models_loaded.get('lstm', False)}, TabNet={models_loaded.get('tabnet', False)}\"\n            print(f\"[DEBUG] {debug_message}\")\n            \n            if progress_callback:\n                progress_callback(10, f\"Getting races to predict... {debug_message}\")\n\n            # Get races to predict\n            if races_to_predict:\n                # Predict specific races\n                total_races = len(races_to_predict)\n                predicted_count = 0\n\n                for i, comp in enumerate(races_to_predict):\n                    if progress_callback:\n                        progress = 10 + (i / total_races) * 80\n                        progress_callback(int(progress), f\"Predicting race {comp}...\")\n\n                    try:\n                        result = predictor.predict_race(comp)\n                        if result.get('status') == 'success':\n                            predicted_count += 1\n                    except Exception as e:\n                        print(f\"Error predicting race {comp}: {str(e)}\")\n                        continue\n            else:\n                # Predict races based on force_reprediction flag\n                if force_reprediction:\n                    # Get all races with processed data (ignore existing predictions)\n                    races_to_process = self.get_races_for_reprediction()\n                    message_type = \"all processed races (force reprediction)\"\n                else:\n                    # Get only unpredicted races\n                    races_to_process = self.get_races_needing_prediction()\n                    message_type = \"unpredicted races\"\n\n                total_races = len(races_to_process)\n                predicted_count = 0\n\n                if total_races == 0:\n                    if progress_callback:\n                        progress_callback(100, f\"No {message_type} found\")\n                    return {\n                        \"success\": True,\n                        \"message\": f\"No {message_type} found\",\n                        \"predicted_count\": 0,\n                        \"total_races\": 0\n                    }\n\n                for i, race in enumerate(races_to_process):\n                    comp = race['comp']\n                    if progress_callback:\n                        progress = 10 + (i / total_races) * 80\n                        progress_callback(int(progress), f\"Predicting race {comp}...\")\n\n                    try:\n                        result = predictor.predict_race(comp)\n                        if result.get('status') == 'success':\n                            predicted_count += 1\n                    except Exception as e:\n                        print(f\"Error predicting race {comp}: {str(e)}\")\n                        continue\n\n                races_to_predict = [race['comp'] for race in races_to_process]\n\n            if progress_callback:\n                progress_callback(100, f\"Predictions completed: {predicted_count}/{len(races_to_predict)} successful\")\n\n            # Add model debug info to the final result\n            final_message = f\"Predictions completed: {predicted_count}/{len(races_to_predict)} successful. {debug_message}\"\n            \n            return {\n                \"success\": True,\n                \"message\": final_message,\n                \"predicted_count\": predicted_count,\n                \"total_races\": len(races_to_predict),\n                \"model_info\": model_info  # Include full model info in response\n            }\n\n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"message\": f\"Prediction failed: {str(e)}\"\n            }\n\n\n\n\n    def evaluate_all_predictions_comprehensive(self, progress_callback=None) -> Dict[str, Any]:\n        \"\"\"Comprehensive evaluation of all predicted races using new PredictEvaluator\"\"\"\n        try:\n            if progress_callback:\n                progress_callback(5, \"Initializing comprehensive evaluation...\")\n\n            # Initialize the new evaluator\n            evaluator = PredictEvaluator()\n\n            if progress_callback:\n                progress_callback(20, \"Getting all evaluable races...\")\n\n            # Get evaluation metrics\n            metrics = evaluator.evaluate_all_races()\n\n            if progress_callback:\n                progress_callback(40, \"Analyzing bet type performance...\")\n\n            # Get bet type wins\n            bet_type_wins = evaluator.get_races_won_by_bet_type()\n\n            if progress_callback:\n                progress_callback(60, \"Analyzing quinte betting strategies...\")\n\n            # Get quinte horse analysis\n            quinte_analysis = evaluator.get_quinte_horse_betting_analysis()\n\n            if progress_callback:\n                progress_callback(80, \"Preparing visualization data...\")\n\n            # Prepare data for charts\n            chart_data = self._prepare_chart_data(metrics, bet_type_wins, quinte_analysis)\n\n            if progress_callback:\n                progress_callback(100, f\"Evaluation completed for {metrics.races_evaluated} races\")\n\n            return {\n                \"success\": True,\n                \"message\": f\"Comprehensive evaluation completed for {metrics.races_evaluated} races\",\n                \"metrics\": metrics,\n                \"bet_type_wins\": bet_type_wins,\n                \"quinte_analysis\": quinte_analysis,\n                \"chart_data\": chart_data\n            }\n\n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"message\": f\"Comprehensive evaluation failed: {str(e)}\"\n            }\n\n    def _prepare_chart_data(self, metrics, bet_type_wins, quinte_analysis):\n        \"\"\"Prepare data for visualization charts\"\"\"\n\n        # Bet type performance chart data\n        bet_performance = []\n        for bet_type, stats in metrics.bet_win_rates.items():\n            if stats['wins'] > 0:  # Only include bet types with wins\n                bet_performance.append({\n                    'bet_type': stats['display_name'],\n                    'wins': stats['wins'],\n                    'total': stats['total'],\n                    'win_rate': stats['rate'] * 100,  # Convert to percentage\n                    'losses': stats['total'] - stats['wins']\n                })\n\n        # Sort by win rate\n        bet_performance.sort(key=lambda x: x['win_rate'], reverse=True)\n\n        # Quinte horse strategy chart data\n        quinte_strategy_data = []\n        if quinte_analysis:\n            scenarios = quinte_analysis['betting_scenarios']\n            for scenario_name, data in scenarios.items():\n                horse_count = scenario_name.replace('_horses', '').replace('_', ' ').title()\n                quinte_strategy_data.append({\n                    'strategy': f\"{horse_count} Horses\",\n                    'wins': data['wins'],\n                    'total': data['total'],\n                    'win_rate': data['win_rate'] * 100,\n                    'losses': data['total'] - data['wins']\n                })\n\n        # Overall performance summary\n        overall_summary = {\n            'total_races': metrics.total_races,\n            'winner_accuracy': metrics.overall_winner_accuracy * 100,\n            'podium_accuracy': metrics.overall_podium_accuracy * 100,\n            'total_winning_bets': metrics.total_winning_bets\n        }\n\n        # Quinte performance summary\n        quinte_summary = None\n        if metrics.quinte_performance:\n            qp = metrics.quinte_performance\n            quinte_summary = {\n                'total_quinte_races': qp['total_quinte_races'],\n                'winner_accuracy': qp['winner_accuracy'] * 100,\n                'quinte_bet_win_rate': qp['quinte_bet_win_rate'] * 100,\n                'avg_podium_accuracy': qp['avg_podium_accuracy'] * 100\n            }\n\n        return {\n            'bet_performance': bet_performance,\n            'quinte_strategy': quinte_strategy_data,\n            'overall_summary': overall_summary,\n            'quinte_summary': quinte_summary\n        }\n\n    def execute_incremental_training(self, date_from: str, date_to: str, limit: int = None,\n                                     update_model: bool = True, create_enhanced: bool = True,\n                                     archive_after: bool = True, progress_callback=None) -> Dict[str, Any]:\n        \"\"\"Execute incremental training using the new IncrementalTrainingPipeline\"\"\"\n        try:\n            if progress_callback:\n                progress_callback(5, \"Initializing incremental training pipeline...\")\n\n            # Initialize the incremental training pipeline\n            pipeline = IncrementalTrainingPipeline(\n                model_path=None,  # Use latest model from config\n                db_name=self.get_active_db(),\n                verbose=True\n            )\n\n            if progress_callback:\n                progress_callback(15, \"Fetching completed races with predictions and results...\")\n\n            # Check how many races are available\n            races = pipeline.fetch_completed_races(date_from, date_to, limit)\n            if not races:\n                return {\n                    \"success\": False,\n                    \"message\": \"No completed races found with both predictions and results\",\n                    \"training_results\": {}\n                }\n\n            if progress_callback:\n                progress_callback(25, f\"Found {len(races)} races. Running incremental training...\")\n\n            # Run the incremental training pipeline\n            results = pipeline.run_incremental_training_pipeline(\n                date_from=date_from,\n                date_to=date_to,\n                limit=limit\n            )\n\n            if progress_callback:\n                progress_callback(85, \"Processing training results...\")\n\n            # Check if training was successful\n            success = results.get(\"status\") == \"success\"\n\n            # Update progress based on results\n            if success:\n                model_saved = results.get(\"model_saved\", {}).get(\"status\") == \"success\"\n                races_archived = results.get(\"races_archived\", {}).get(\"status\") == \"success\"\n\n                if model_saved:\n                    if progress_callback:\n                        progress_callback(95, \"Model saved successfully...\")\n\n                if races_archived:\n                    if progress_callback:\n                        progress_callback(98, \"Races archived successfully...\")\n\n            if progress_callback:\n                progress_callback(100, \"Incremental training completed!\")\n\n            # Format results for UI consumption\n            formatted_results = {\n                \"success\": success,\n                \"message\": self._format_training_message(results),\n                \"training_results\": {\n                    \"performance_analysis\": results.get(\"performance_analysis\", {}),\n                    \"rf_training\": results.get(\"rf_training\", {}),\n                    \"lstm_training\": results.get(\"lstm_training\", {}),\n                    \"model_saved\": results.get(\"model_saved\", {}),\n                    \"races_archived\": results.get(\"races_archived\", {}),\n                    \"execution_time\": results.get(\"execution_time\", 0),\n                    \"races_processed\": results.get(\"races_fetched\", 0),\n                    \"training_samples\": results.get(\"training_data_extracted\", 0)\n                }\n            }\n\n            return formatted_results\n\n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"message\": f\"Incremental training failed: {str(e)}\",\n                \"training_results\": {}\n            }\n\n    def _format_training_message(self, results: Dict[str, Any]) -> str:\n        \"\"\"Format a user-friendly message based on training results\"\"\"\n        if results.get(\"status\") != \"success\":\n            return results.get(\"message\", \"Training failed\")\n\n        races_count = results.get(\"races_fetched\", 0)\n        samples_count = results.get(\"training_data_extracted\", 0)\n\n        message_parts = [f\"Processed {races_count} races with {samples_count} training samples\"]\n\n        # RF training results\n        rf_results = results.get(\"rf_training\", {})\n        if rf_results.get(\"status\") == \"success\":\n            rf_improvement = rf_results.get(\"improvement\", {})\n            mae_improvement = rf_improvement.get(\"mae_improvement_pct\", 0)\n            message_parts.append(f\"RF model improved by {mae_improvement:.1f}%\")\n\n        # LSTM training results\n        lstm_results = results.get(\"lstm_training\", {})\n        if lstm_results.get(\"status\") == \"success\":\n            lstm_improvement = lstm_results.get(\"improvement\", {})\n            mae_improvement = lstm_improvement.get(\"mae_improvement_pct\", 0)\n            message_parts.append(f\"LSTM model improved by {mae_improvement:.1f}%\")\n        elif lstm_results.get(\"status\") == \"skipped\":\n            message_parts.append(\"LSTM training skipped\")\n\n        # Model saving results\n        model_saved = results.get(\"model_saved\", {})\n        if model_saved.get(\"status\") == \"success\":\n            version = model_saved.get(\"version\", \"unknown\")\n            message_parts.append(f\"New model saved: {version}\")\n\n        # Archive results\n        archived = results.get(\"races_archived\", {})\n        if archived.get(\"status\") == \"success\":\n            archived_count = archived.get(\"successful\", 0)\n            message_parts.append(f\"Archived {archived_count} races\")\n\n        return \". \".join(message_parts)\n\n    def get_races_with_results(self, date_from: str, date_to: str) -> List[Dict[str, Any]]:\n        \"\"\"Get races that have both predictions and results for the incremental training UI\"\"\"\n        try:\n            # Use the pipeline to get completed races\n            pipeline = IncrementalTrainingPipeline(\n                model_path=None,\n                db_name=self.get_active_db(),\n                verbose=False\n            )\n\n            races = pipeline.fetch_completed_races(date_from, date_to)\n            return races\n\n        except Exception as e:\n            print(f\"Error getting races with results: {e}\")\n            return []\n\n    def get_ai_betting_advice(self, lm_studio_url: str = None, verbose: bool = False) -> Dict[str, Any]:\n        \"\"\"Get AI betting advice based on latest evaluation results\"\"\"\n        try:\n            # Initialize the evaluator to get comprehensive results\n            evaluator = PredictEvaluator()\n            \n            # Get evaluation metrics\n            metrics = evaluator.evaluate_all_races()\n            \n            # Get bet type wins\n            bet_type_wins = evaluator.get_races_won_by_bet_type()\n            \n            # Get quinte analysis\n            quinte_analysis = evaluator.get_quinte_horse_betting_analysis()\n            \n            # Format evaluation results for AI advisor\n            evaluation_results = self._format_results_for_advisor(metrics, bet_type_wins, quinte_analysis)\n            \n            # Initialize AI advisor (will use config if lm_studio_url is None)\n            advisor = BettingAdvisor(lm_studio_url=lm_studio_url, verbose=verbose)\n            \n            # Get AI advice\n            ai_advice = advisor.analyze_daily_results(evaluation_results)\n            \n            return {\n                \"success\": True,\n                \"message\": \"AI betting advice generated successfully\",\n                \"ai_advice\": ai_advice,\n                \"evaluation_data\": evaluation_results\n            }\n            \n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"message\": f\"Failed to get AI betting advice: {str(e)}\"\n            }\n\n    def get_ai_race_advice(self, race_comp: str, lm_studio_url: str = None, verbose: bool = False) -> Dict[str, Any]:\n        \"\"\"Get AI advice for a specific race\"\"\"\n        try:\n            # Get race data and predictions\n            race_fetcher = RaceFetcher()\n            race_data = race_fetcher.get_race_by_comp(race_comp)\n            \n            if not race_data:\n                return {\n                    \"success\": False,\n                    \"message\": f\"Race {race_comp} not found\"\n                }\n            \n            # Get prediction results from race data\n            prediction_results = race_data.get('prediction_results')\n            \n            if not prediction_results:\n                return {\n                    \"success\": False,\n                    \"message\": f\"No predictions found for race {race_comp}\"\n                }\n            \n            # Parse prediction results if they're stored as JSON string\n            if isinstance(prediction_results, str):\n                try:\n                    prediction_results = json.loads(prediction_results)\n                except json.JSONDecodeError:\n                    return {\n                        \"success\": False,\n                        \"message\": f\"Invalid prediction results format for race {race_comp}\"\n                    }\n            \n            # Get previous results for context\n            evaluator = PredictEvaluator()\n            previous_results = evaluator.evaluate_all_races()\n            previous_results_dict = self._format_results_for_advisor(previous_results, {}, {})\n            \n            # Initialize AI advisor (will use config if lm_studio_url is None)\n            advisor = BettingAdvisor(lm_studio_url=lm_studio_url, verbose=verbose)\n            \n            # Get AI race advice\n            ai_advice = advisor.analyze_race_prediction(race_data, prediction_results, previous_results_dict)\n            \n            return {\n                \"success\": True,\n                \"message\": \"AI race advice generated successfully\",\n                \"ai_advice\": ai_advice,\n                \"race_data\": race_data,\n                \"predictions\": prediction_results\n            }\n            \n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"message\": f\"Failed to get AI race advice: {str(e)}\"\n            }\n\n    def _format_results_for_advisor(self, metrics, bet_type_wins, quinte_analysis) -> Dict[str, Any]:\n        \"\"\"Format evaluation results for AI advisor consumption\"\"\"\n        # Convert metrics object to dictionary format expected by advisor\n        formatted_results = {\n            'summary_metrics': {\n                'total_races': metrics.total_races,\n                'winner_accuracy': metrics.overall_winner_accuracy,\n                'podium_accuracy': metrics.overall_podium_accuracy,\n                'mean_rank_error': getattr(metrics, 'mean_rank_error', 0)\n            },\n            'pmu_summary': {},\n            'race_details': []\n        }\n        \n        # Format bet type wins into PMU summary format\n        if hasattr(metrics, 'bet_win_rates'):\n            for bet_type, stats in metrics.bet_win_rates.items():\n                formatted_results['pmu_summary'][f'{bet_type}_rate'] = stats.get('rate', 0)\n        \n        # Add quinte analysis\n        if quinte_analysis:\n            formatted_results['quinte_analysis'] = quinte_analysis\n            \n        # Add race details if available\n        if bet_type_wins:\n            formatted_results['race_details'] = bet_type_wins\n            \n        return formatted_results\n\n    def get_prediction_model_info(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive information about the three-model prediction system\"\"\"\n        try:\n            # Initialize prediction orchestrator to get model info\n            predictor = PredictionOrchestrator()\n            model_info = predictor.get_model_info()\n            \n            # Get blend configuration from config\n            blend_config = self._config_data.get('blend', {}) if self._config_data else {}\n            \n            # Format comprehensive model information\n            prediction_info = {\n                'ensemble_type': 'Three-Model Ensemble (RF + LSTM + TabNet)',\n                'blend_weights': {\n                    'rf_weight': blend_config.get('rf_weight', 0.8),\n                    'lstm_weight': blend_config.get('lstm_weight', 0.1),\n                    'tabnet_weight': blend_config.get('tabnet_weight', 0.1)\n                },\n                'optimal_mae': blend_config.get('optimal_mae', 11.78),\n                'model_status': {\n                    'rf_loaded': model_info.get('has_rf', False),\n                    'lstm_loaded': model_info.get('has_lstm', False),\n                    'tabnet_loaded': model_info.get('has_tabnet', False)\n                },\n                'model_path': model_info.get('model_path', 'Unknown'),\n                'tabnet_info': {\n                    'available': model_info.get('tabnet_available', False),\n                    'expected_features': model_info.get('expected_tabnet_features', 0)\n                },\n                'system_status': 'operational' if any(model_info.get(k, False) for k in ['has_rf', 'has_lstm', 'has_tabnet']) else 'no_models_loaded'\n            }\n            \n            return {\n                \"success\": True,\n                \"message\": \"Model information retrieved successfully\",\n                \"prediction_info\": prediction_info\n            }\n            \n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"message\": f\"Failed to get model information: {str(e)}\"\n            }\n\n    def get_ai_quinte_advice(self, lm_studio_url: str = None, verbose: bool = False) -> Dict[str, Any]:\n        \"\"\"Get AI betting advice specifically focused on quinte races with 3 refined recommendations\"\"\"\n        try:\n            # Initialize the evaluator to get comprehensive results\n            evaluator = PredictEvaluator()\n            \n            # Get evaluation metrics\n            metrics = evaluator.evaluate_all_races()\n            \n            # Get bet type wins\n            bet_type_wins = evaluator.get_races_won_by_bet_type()\n            \n            # Get quinte analysis - this is the main focus\n            quinte_analysis = evaluator.get_quinte_horse_betting_analysis()\n            \n            # Format evaluation results for AI advisor\n            evaluation_results = self._format_results_for_advisor(metrics, bet_type_wins, quinte_analysis)\n            \n            # Initialize AI advisor (will use config if lm_studio_url is None)\n            advisor = BettingAdvisor(lm_studio_url=lm_studio_url, verbose=verbose)\n            \n            # Get AI advice specifically for quinte\n            ai_advice = advisor.analyze_quinte_betting_strategy(evaluation_results)\n            \n            return {\n                \"success\": True,\n                \"message\": \"AI quinte betting advice generated successfully\",\n                \"ai_advice\": ai_advice,\n                \"evaluation_data\": evaluation_results\n            }\n            \n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"message\": f\"Failed to get AI quinte betting advice: {str(e)}\"\n            }
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/UI/UIhelper.py b/UI/UIhelper.py
--- a/UI/UIhelper.py	(revision 1a3a9d2b2ad9fdaf3f15b7dd71bf4526413a914c)
+++ b/UI/UIhelper.py	(date 1759478552011)
@@ -831,4 +831,476 @@
                 "success": False,
                 "error": str(e),
                 "message": f"Failed to get AI quinte betting advice: {str(e)}"
+            }
+
+    def load_weight_analysis_data(self, date_from: str = None, date_to: str = None,
+                                   race_filters: Dict[str, Any] = None) -> Dict[str, Any]:
+        """Load race predictions and metadata for weight analysis"""
+        try:
+            # Connect directly to database without loading models
+            from utils.env_setup import AppConfig
+            import sqlite3
+
+            config = AppConfig()
+            db_path = config.get_active_database_path()
+            conn = sqlite3.connect(db_path)
+
+            # Build query with filters
+            query = """
+                SELECT
+                    rp.race_comp,
+                    rp.numero,
+                    rp.rf_prediction,
+                    rp.tabnet_prediction,
+                    rp.actual_result,
+                    rp.predicted_at,
+                    hr.typec,
+                    hr.dist,
+                    hr.partant,
+                    hr.hippo,
+                    hr.montant
+                FROM race_predictions rp
+                JOIN historical_race hr ON rp.race_comp = hr.comp
+                WHERE rp.actual_result IS NOT NULL
+                  AND rp.rf_prediction IS NOT NULL
+                  AND rp.tabnet_prediction IS NOT NULL
+            """
+
+            params = []
+
+            # Date filters
+            if date_from:
+                query += " AND date(rp.predicted_at) >= ?"
+                params.append(date_from)
+            if date_to:
+                query += " AND date(rp.predicted_at) <= ?"
+                params.append(date_to)
+
+            # Race characteristic filters
+            if race_filters:
+                if race_filters.get('typec'):
+                    query += " AND hr.typec = ?"
+                    params.append(race_filters['typec'])
+                if race_filters.get('min_dist'):
+                    query += " AND hr.dist >= ?"
+                    params.append(race_filters['min_dist'])
+                if race_filters.get('max_dist'):
+                    query += " AND hr.dist <= ?"
+                    params.append(race_filters['max_dist'])
+                if race_filters.get('min_partant'):
+                    query += " AND hr.partant >= ?"
+                    params.append(race_filters['min_partant'])
+                if race_filters.get('max_partant'):
+                    query += " AND hr.partant <= ?"
+                    params.append(race_filters['max_partant'])
+                if race_filters.get('hippo'):
+                    query += " AND hr.hippo = ?"
+                    params.append(race_filters['hippo'])
+
+            query += " ORDER BY rp.predicted_at DESC"
+
+            import pandas as pd
+            df = pd.read_sql_query(query, conn, params=params)
+
+            return {
+                "success": True,
+                "data": df,
+                "message": f"Loaded {len(df)} predictions from {df['race_comp'].nunique()} races"
+            }
+
+        except Exception as e:
+            return {
+                "success": False,
+                "error": str(e),
+                "message": f"Failed to load weight analysis data: {str(e)}"
+            }
+
+    def test_weight_combinations(self, data_df, weight_step: float = 0.1) -> Dict[str, Any]:
+        """Test all RF/TabNet weight combinations and calculate metrics"""
+        try:
+            import numpy as np
+
+            results = []
+
+            # Generate weight combinations (RF + TabNet = 1.0)
+            for rf_weight in np.arange(0.0, 1.01, weight_step):
+                tabnet_weight = 1.0 - rf_weight
+
+                # Calculate blended predictions
+                data_df['blended_prediction'] = (
+                    data_df['rf_prediction'] * rf_weight +
+                    data_df['tabnet_prediction'] * tabnet_weight
+                )
+
+                # Group by race to calculate accuracy
+                races_grouped = data_df.groupby('race_comp')
+
+                winner_correct = 0
+                podium_correct = 0
+                total_races = 0
+
+                mae_list = []
+                rmse_list = []
+
+                for race_comp, race_data in races_grouped:
+                    total_races += 1
+
+                    # Sort by blended prediction
+                    race_data_sorted = race_data.sort_values('blended_prediction')
+                    race_data_sorted['predicted_position'] = range(1, len(race_data_sorted) + 1)
+
+                    # Check winner accuracy
+                    predicted_winner = race_data_sorted.iloc[0]['numero']
+                    actual_winner_data = race_data[race_data['actual_result'] == 1]
+                    if len(actual_winner_data) > 0:
+                        actual_winner = actual_winner_data.iloc[0]['numero']
+                        if predicted_winner == actual_winner:
+                            winner_correct += 1
+
+                    # Check podium accuracy (top 3)
+                    predicted_podium = set(race_data_sorted.head(3)['numero'].values)
+                    actual_podium_data = race_data[race_data['actual_result'] <= 3]
+                    if len(actual_podium_data) >= 3:
+                        actual_podium = set(actual_podium_data['numero'].values)
+                        if len(predicted_podium & actual_podium) == 3:
+                            podium_correct += 1
+
+                    # Calculate MAE and RMSE
+                    for _, row in race_data_sorted.iterrows():
+                        predicted_pos = row['predicted_position']
+                        actual_pos = row['actual_result']
+                        error = abs(predicted_pos - actual_pos)
+                        mae_list.append(error)
+                        rmse_list.append(error ** 2)
+
+                # Calculate aggregate metrics
+                winner_accuracy = winner_correct / total_races if total_races > 0 else 0
+                podium_accuracy = podium_correct / total_races if total_races > 0 else 0
+                mae = np.mean(mae_list) if mae_list else 0
+                rmse = np.sqrt(np.mean(rmse_list)) if rmse_list else 0
+
+                results.append({
+                    'rf_weight': round(rf_weight, 2),
+                    'tabnet_weight': round(tabnet_weight, 2),
+                    'winner_accuracy': winner_accuracy,
+                    'podium_accuracy': podium_accuracy,
+                    'mae': mae,
+                    'rmse': rmse,
+                    'total_races': total_races
+                })
+
+            return {
+                "success": True,
+                "results": results,
+                "message": f"Tested {len(results)} weight combinations"
+            }
+
+        except Exception as e:
+            return {
+                "success": False,
+                "error": str(e),
+                "message": f"Failed to test weight combinations: {str(e)}"
+            }
+
+    def analyze_by_race_characteristics(self, data_df, optimal_weights: Dict[str, float] = None) -> Dict[str, Any]:
+        """Analyze performance breakdown by race characteristics"""
+        try:
+            import numpy as np
+
+            if optimal_weights is None:
+                optimal_weights = {'rf_weight': 0.8, 'tabnet_weight': 0.2}
+
+            # Calculate blended predictions with optimal weights
+            data_df['blended_prediction'] = (
+                data_df['rf_prediction'] * optimal_weights['rf_weight'] +
+                data_df['tabnet_prediction'] * optimal_weights['tabnet_weight']
+            )
+
+            analysis_results = {}
+
+            # Analysis by race type (typec)
+            analysis_results['by_typec'] = self._analyze_by_characteristic(
+                data_df, 'typec', optimal_weights
+            )
+
+            # Analysis by distance buckets
+            data_df['dist_bucket'] = pd.cut(
+                data_df['dist'],
+                bins=[0, 1500, 2000, 2500, 3000, 10000],
+                labels=['<1500m', '1500-2000m', '2000-2500m', '2500-3000m', '>3000m']
+            )
+            analysis_results['by_distance'] = self._analyze_by_characteristic(
+                data_df, 'dist_bucket', optimal_weights
+            )
+
+            # Analysis by field size buckets
+            data_df['field_bucket'] = pd.cut(
+                data_df['partant'],
+                bins=[0, 8, 12, 16, 30],
+                labels=['Small (≤8)', 'Medium (9-12)', 'Large (13-16)', 'Very Large (>16)']
+            )
+            analysis_results['by_field_size'] = self._analyze_by_characteristic(
+                data_df, 'field_bucket', optimal_weights
+            )
+
+            # Analysis by purse level buckets
+            data_df['purse_bucket'] = pd.cut(
+                data_df['montant'],
+                bins=[0, 20000, 50000, 100000, 1000000],
+                labels=['Low (<20k)', 'Medium (20-50k)', 'High (50-100k)', 'Premium (>100k)']
+            )
+            analysis_results['by_purse'] = self._analyze_by_characteristic(
+                data_df, 'purse_bucket', optimal_weights
+            )
+
+            # Top 5 hippodromes by race count
+            top_hippos = data_df['hippo'].value_counts().head(5).index.tolist()
+            data_df_top_hippos = data_df[data_df['hippo'].isin(top_hippos)]
+            analysis_results['by_hippo'] = self._analyze_by_characteristic(
+                data_df_top_hippos, 'hippo', optimal_weights
+            )
+
+            return {
+                "success": True,
+                "analysis": analysis_results,
+                "message": "Race characteristic analysis completed"
+            }
+
+        except Exception as e:
+            return {
+                "success": False,
+                "error": str(e),
+                "message": f"Failed to analyze by race characteristics: {str(e)}"
+            }
+
+    def _analyze_by_characteristic(self, data_df, characteristic: str, optimal_weights: Dict[str, float]) -> List[Dict[str, Any]]:
+        """Helper function to analyze performance by a specific characteristic"""
+        import numpy as np
+
+        results = []
+
+        for char_value, char_data in data_df.groupby(characteristic):
+            if pd.isna(char_value):
+                continue
+
+            races_grouped = char_data.groupby('race_comp')
+
+            winner_correct = 0
+            podium_correct = 0
+            total_races = 0
+            mae_list = []
+
+            for race_comp, race_data in races_grouped:
+                total_races += 1
+
+                # Sort by blended prediction
+                race_data_sorted = race_data.sort_values('blended_prediction')
+                race_data_sorted['predicted_position'] = range(1, len(race_data_sorted) + 1)
+
+                # Check winner accuracy
+                predicted_winner = race_data_sorted.iloc[0]['numero']
+                actual_winner_data = race_data[race_data['actual_result'] == 1]
+                if len(actual_winner_data) > 0:
+                    actual_winner = actual_winner_data.iloc[0]['numero']
+                    if predicted_winner == actual_winner:
+                        winner_correct += 1
+
+                # Check podium accuracy
+                predicted_podium = set(race_data_sorted.head(3)['numero'].values)
+                actual_podium_data = race_data[race_data['actual_result'] <= 3]
+                if len(actual_podium_data) >= 3:
+                    actual_podium = set(actual_podium_data['numero'].values)
+                    if len(predicted_podium & actual_podium) == 3:
+                        podium_correct += 1
+
+                # Calculate MAE
+                for _, row in race_data_sorted.iterrows():
+                    predicted_pos = row['predicted_position']
+                    actual_pos = row['actual_result']
+                    mae_list.append(abs(predicted_pos - actual_pos))
+
+            winner_accuracy = winner_correct / total_races if total_races > 0 else 0
+            podium_accuracy = podium_correct / total_races if total_races > 0 else 0
+            mae = np.mean(mae_list) if mae_list else 0
+
+            results.append({
+                'characteristic_value': str(char_value),
+                'winner_accuracy': winner_accuracy,
+                'podium_accuracy': podium_accuracy,
+                'mae': mae,
+                'total_races': total_races
+            })
+
+        return results
+
+    def detect_weight_patterns(self, data_df, weight_step: float = 0.1) -> Dict[str, Any]:
+        """Automated pattern detection: test all weights and find optimal patterns by race features"""
+        try:
+            import numpy as np
+
+            # Step 1: Test all weight combinations
+            weight_test_result = self.test_weight_combinations(data_df.copy(), weight_step)
+            if not weight_test_result['success']:
+                return weight_test_result
+
+            weight_results = weight_test_result['results']
+
+            # Step 2: Find overall best weights
+            best_overall = max(weight_results, key=lambda x: x['winner_accuracy'])
+
+            # Step 3: Test different weights for each race characteristic
+            patterns = {
+                'overall_best': {
+                    'rf_weight': best_overall['rf_weight'],
+                    'tabnet_weight': best_overall['tabnet_weight'],
+                    'winner_accuracy': best_overall['winner_accuracy'],
+                    'podium_accuracy': best_overall['podium_accuracy'],
+                    'mae': best_overall['mae'],
+                    'total_races': best_overall['total_races']
+                },
+                'by_race_type': [],
+                'by_distance_range': [],
+                'by_field_size': [],
+                'by_purse_level': [],
+                'summary': []
+            }
+
+            # Pattern detection for race types
+            for typec in data_df['typec'].unique():
+                if pd.isna(typec):
+                    continue
+
+                typec_data = data_df[data_df['typec'] == typec].copy()
+                if len(typec_data) < 10:  # Skip if too few races
+                    continue
+
+                typec_results = self.test_weight_combinations(typec_data, weight_step)
+                if typec_results['success']:
+                    best_for_typec = max(typec_results['results'], key=lambda x: x['winner_accuracy'])
+
+                    # Only include if weights differ from overall by 0.2+ OR accuracy improvement > 5%
+                    weight_diff = abs(best_for_typec['rf_weight'] - best_overall['rf_weight'])
+                    accuracy_improvement = best_for_typec['winner_accuracy'] - best_overall['winner_accuracy']
+
+                    if weight_diff >= 0.2 or accuracy_improvement > 0.05:
+                        patterns['by_race_type'].append({
+                            'typec': typec,
+                            'optimal_rf_weight': best_for_typec['rf_weight'],
+                            'optimal_tabnet_weight': best_for_typec['tabnet_weight'],
+                            'winner_accuracy': best_for_typec['winner_accuracy'],
+                            'improvement_vs_overall': accuracy_improvement,
+                            'total_races': best_for_typec['total_races'],
+                            'recommendation': 'Use custom weights' if weight_diff >= 0.2 else 'Overall weights work well'
+                        })
+
+            # Pattern detection for distance ranges
+            data_df['dist_bucket'] = pd.cut(
+                data_df['dist'],
+                bins=[0, 1500, 2000, 2500, 3000, 10000],
+                labels=['<1500m', '1500-2000m', '2000-2500m', '2500-3000m', '>3000m']
+            )
+
+            for dist_range in data_df['dist_bucket'].unique():
+                if pd.isna(dist_range):
+                    continue
+
+                dist_data = data_df[data_df['dist_bucket'] == dist_range].copy()
+                if len(dist_data) < 10:
+                    continue
+
+                dist_results = self.test_weight_combinations(dist_data, weight_step)
+                if dist_results['success']:
+                    best_for_dist = max(dist_results['results'], key=lambda x: x['winner_accuracy'])
+
+                    weight_diff = abs(best_for_dist['rf_weight'] - best_overall['rf_weight'])
+                    accuracy_improvement = best_for_dist['winner_accuracy'] - best_overall['winner_accuracy']
+
+                    if weight_diff >= 0.2 or accuracy_improvement > 0.05:
+                        patterns['by_distance_range'].append({
+                            'distance_range': str(dist_range),
+                            'optimal_rf_weight': best_for_dist['rf_weight'],
+                            'optimal_tabnet_weight': best_for_dist['tabnet_weight'],
+                            'winner_accuracy': best_for_dist['winner_accuracy'],
+                            'improvement_vs_overall': accuracy_improvement,
+                            'total_races': best_for_dist['total_races'],
+                            'recommendation': 'Use custom weights' if weight_diff >= 0.2 else 'Overall weights work well'
+                        })
+
+            # Pattern detection for field size
+            data_df['field_bucket'] = pd.cut(
+                data_df['partant'],
+                bins=[0, 8, 12, 16, 30],
+                labels=['Small (≤8)', 'Medium (9-12)', 'Large (13-16)', 'Very Large (>16)']
+            )
+
+            for field_size in data_df['field_bucket'].unique():
+                if pd.isna(field_size):
+                    continue
+
+                field_data = data_df[data_df['field_bucket'] == field_size].copy()
+                if len(field_data) < 10:
+                    continue
+
+                field_results = self.test_weight_combinations(field_data, weight_step)
+                if field_results['success']:
+                    best_for_field = max(field_results['results'], key=lambda x: x['winner_accuracy'])
+
+                    weight_diff = abs(best_for_field['rf_weight'] - best_overall['rf_weight'])
+                    accuracy_improvement = best_for_field['winner_accuracy'] - best_overall['winner_accuracy']
+
+                    if weight_diff >= 0.2 or accuracy_improvement > 0.05:
+                        patterns['by_field_size'].append({
+                            'field_size': str(field_size),
+                            'optimal_rf_weight': best_for_field['rf_weight'],
+                            'optimal_tabnet_weight': best_for_field['tabnet_weight'],
+                            'winner_accuracy': best_for_field['winner_accuracy'],
+                            'improvement_vs_overall': accuracy_improvement,
+                            'total_races': best_for_field['total_races'],
+                            'recommendation': 'Use custom weights' if weight_diff >= 0.2 else 'Overall weights work well'
+                        })
+
+            # Generate summary insights
+            total_patterns = len(patterns['by_race_type']) + len(patterns['by_distance_range']) + len(patterns['by_field_size'])
+
+            if total_patterns == 0:
+                patterns['summary'].append({
+                    'type': 'no_patterns',
+                    'message': f"Overall weights ({best_overall['rf_weight']:.1f} RF / {best_overall['tabnet_weight']:.1f} TabNet) work well across all race types"
+                })
+            else:
+                patterns['summary'].append({
+                    'type': 'patterns_found',
+                    'message': f"Found {total_patterns} significant patterns requiring custom weights"
+                })
+
+            if len(patterns['by_race_type']) > 0:
+                patterns['summary'].append({
+                    'type': 'race_type_patterns',
+                    'message': f"Race type matters: {len(patterns['by_race_type'])} types benefit from custom weights"
+                })
+
+            if len(patterns['by_distance_range']) > 0:
+                patterns['summary'].append({
+                    'type': 'distance_patterns',
+                    'message': f"Distance matters: {len(patterns['by_distance_range'])} ranges benefit from custom weights"
+                })
+
+            if len(patterns['by_field_size']) > 0:
+                patterns['summary'].append({
+                    'type': 'field_size_patterns',
+                    'message': f"Field size matters: {len(patterns['by_field_size'])} sizes benefit from custom weights"
+                })
+
+            return {
+                "success": True,
+                "patterns": patterns,
+                "all_weight_results": weight_results,
+                "message": f"Pattern detection complete: found {total_patterns} significant patterns"
+            }
+
+        except Exception as e:
+            return {
+                "success": False,
+                "error": str(e),
+                "message": f"Failed to detect patterns: {str(e)}"
             }
\ No newline at end of file
